{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src import runner\n",
    "from src import gen_spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct sequence fall off detection\n",
    "We have a property in the program that lets us pass in a \"truth\" set. This truth set we will pull from Delong lab and will primarily be used for debugging our hybrids. The steps we need to take:\n",
    "1. Load in SpectrumMill results and create a \"truth\" set where each entry in this json file has the form:\n",
    "```json\n",
    "{\n",
    "    spectrum_id: {\n",
    "        \"sequence\": str, \n",
    "        \"hybrid\": bool, \n",
    "        \"parent\": str\n",
    "    }\n",
    "}\n",
    "```\n",
    "2. Run hyped search with the \"truth_set\" param set to the file generated in step 1\n",
    "3. Load in the file created (output_dir + 'fall_off.json')\n",
    "4. Run all analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_file = '/Users/zacharymcgrath/Desktop/nod2 data/filteredSpec/'\n",
    "db_file = '/Users/zacharymcgrath/Desktop/nod2 data/filteredNOD2.fasta'\n",
    "output_dir = '/Users/zacharymcgrath/Desktop/Experiment output/fall_off/'\n",
    "specmil_truth_set = '/Users/zacharymcgrath/Downloads/NOD2_E3_results.ssv'\n",
    "\n",
    "minPep = 3\n",
    "maxPep = 30\n",
    "tolerance = 20\n",
    "relative_abundance_filter = 0.0\n",
    "precursor_tolerance = 10\n",
    "peak_filter = 25\n",
    "verbose = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in SpectrumMill and create truth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>filename</th>\n",
       "      <th>parent_charge</th>\n",
       "      <th>score</th>\n",
       "      <th>deltaForwardReverseScore</th>\n",
       "      <th>deltaRank1Rank2Score</th>\n",
       "      <th>percent_scored_peak_intensity</th>\n",
       "      <th>totalIntensity</th>\n",
       "      <th>previous_aa</th>\n",
       "      <th>sequence</th>\n",
       "      <th>next_aa</th>\n",
       "      <th>retentionTimeMin</th>\n",
       "      <th>chromatographicPeakWidthSec</th>\n",
       "      <th>parent_m_over_z</th>\n",
       "      <th>species</th>\n",
       "      <th>entry_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NOD2_E3.13446.13477.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.10</td>\n",
       "      <td>9.91</td>\n",
       "      <td>84.5</td>\n",
       "      <td>183000.0</td>\n",
       "      <td>(E)</td>\n",
       "      <td>DPQVEQLEL</td>\n",
       "      <td>(-)</td>\n",
       "      <td>48.35</td>\n",
       "      <td>26.0</td>\n",
       "      <td>535.7725</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>ins1C18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NOD2_E3.18005.18246.2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.84</td>\n",
       "      <td>11.07</td>\n",
       "      <td>12.84</td>\n",
       "      <td>97.8</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>(G)</td>\n",
       "      <td>DLQTLALEVA</td>\n",
       "      <td>(-)</td>\n",
       "      <td>65.78</td>\n",
       "      <td>29.0</td>\n",
       "      <td>536.8007</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>ins1C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NOD2_E3.13729.13828.2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.43</td>\n",
       "      <td>6.68</td>\n",
       "      <td>7.86</td>\n",
       "      <td>90.7</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>(G)</td>\n",
       "      <td>DLQTLALE</td>\n",
       "      <td>(-)</td>\n",
       "      <td>49.52</td>\n",
       "      <td>22.0</td>\n",
       "      <td>451.7460</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>ins1C5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NOD2_E3.15226.15503.2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.17</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6.67</td>\n",
       "      <td>89.1</td>\n",
       "      <td>1740000.0</td>\n",
       "      <td>(G)</td>\n",
       "      <td>DLQTLAL</td>\n",
       "      <td>(-)</td>\n",
       "      <td>54.38</td>\n",
       "      <td>169.0</td>\n",
       "      <td>387.2243</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>ins1C6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NOD2_E3.21510.21510.2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.54</td>\n",
       "      <td>12.54</td>\n",
       "      <td>12.54</td>\n",
       "      <td>91.3</td>\n",
       "      <td>91900.0</td>\n",
       "      <td>(G)</td>\n",
       "      <td>DLQTLALLL</td>\n",
       "      <td>(D)</td>\n",
       "      <td>76.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500.3081</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>HYBRID: mouse ins1C PQVEQLELGGSPGDLQTLAL-LLDEG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number               filename  parent_charge  score  \\\n",
       "0       1  NOD2_E3.13446.13477.2              2  10.10   \n",
       "1       2  NOD2_E3.18005.18246.2              2  12.84   \n",
       "2       3  NOD2_E3.13729.13828.2              2  12.43   \n",
       "3       4  NOD2_E3.15226.15503.2              2  11.17   \n",
       "4       5  NOD2_E3.21510.21510.2              2  12.54   \n",
       "\n",
       "   deltaForwardReverseScore  deltaRank1Rank2Score  \\\n",
       "0                     10.10                  9.91   \n",
       "1                     11.07                 12.84   \n",
       "2                      6.68                  7.86   \n",
       "3                      6.21                  6.67   \n",
       "4                     12.54                 12.54   \n",
       "\n",
       "   percent_scored_peak_intensity  totalIntensity previous_aa    sequence  \\\n",
       "0                           84.5        183000.0         (E)   DPQVEQLEL   \n",
       "1                           97.8      40000000.0         (G)  DLQTLALEVA   \n",
       "2                           90.7       2200000.0         (G)    DLQTLALE   \n",
       "3                           89.1       1740000.0         (G)     DLQTLAL   \n",
       "4                           91.3         91900.0         (G)   DLQTLALLL   \n",
       "\n",
       "  next_aa  retentionTimeMin  chromatographicPeakWidthSec  parent_m_over_z  \\\n",
       "0     (-)             48.35                         26.0         535.7725   \n",
       "1     (-)             65.78                         29.0         536.8007   \n",
       "2     (-)             49.52                         22.0         451.7460   \n",
       "3     (-)             54.38                        169.0         387.2243   \n",
       "4     (D)             76.92                          3.0         500.3081   \n",
       "\n",
       "  species                                         entry_name  \n",
       "0   MOUSE                                            ins1C18  \n",
       "1   MOUSE                                             ins1C3  \n",
       "2   MOUSE                                             ins1C5  \n",
       "3   MOUSE                                             ins1C6  \n",
       "4   MOUSE  HYBRID: mouse ins1C PQVEQLELGGSPGDLQTLAL-LLDEG...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first load in the results\n",
    "specmil_results = pd.read_csv(specmil_truth_set, sep=';')\n",
    "specmil_results.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_seq(peptide: str, protein: str) -> str:\n",
    "    '''\n",
    "    From a hybrid protein that looks like \n",
    "    ABCDE-FGHI\n",
    "    \n",
    "    and a peptide that looks like\n",
    "    DEFGH\n",
    "    \n",
    "    extract \n",
    "    DE-FGH\n",
    "    \n",
    "    Inputs:\n",
    "        peptide: (str) the desired subseq\n",
    "        protein: (str) the full string with the hybrid character \n",
    "    Outputs:\n",
    "        new peptide string\n",
    "    '''\n",
    "    # copy the protein\n",
    "    prot_cp = copy.deepcopy(protein)\n",
    "    \n",
    "    # find the subseq\n",
    "    peptide_idx = protein.replace('-', '').replace('(', '').replace(')', '').index(peptide)\n",
    "    \n",
    "    # get that stretch of prot\n",
    "    add_on = len(peptide) + (1 if '-' in protein else 2)\n",
    "    \n",
    "    return protein[peptide_idx:peptide_idx+add_on]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json to store results in\n",
    "json_truth_set = {}\n",
    "\n",
    "# go through every entry in the database, find out if its a hybrid and get the sequence, ided by the filename\n",
    "for idx, row in specmil_results.iterrows():\n",
    "    \n",
    "    # all the ids seem to have .pkl at the end of them so add that\n",
    "    key = row['filename'] + '.pkl'\n",
    "    hybrid = 'HYBRID' in row['entry_name']\n",
    "    \n",
    "    seq = row['sequence'] if not hybrid else get_hybrid_seq(row['sequence'], row['entry_name'])\n",
    "    \n",
    "    json_truth_set[key] = {\n",
    "        'hybrid': hybrid, \n",
    "        'sequence': seq, \n",
    "        'parent': row['entry_name']\n",
    "    }\n",
    "    \n",
    "full_truth_path = output_dir + 'specmil_truth_set.json'\n",
    "    \n",
    "json.dump(json_truth_set, open(full_truth_path, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run hypedsearch with the truth set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEV set to True. \n",
      "Tracking when correct answer falls off. \n",
      "Results are stored in a json named 'fall_off.json' in the specified output directory\n",
      "File will be of the form\n",
      "\n",
      "    {\n",
      "        spectrum_id: {\n",
      "            hybrid: bool, \n",
      "            truth_sequence: str, \n",
      "            fall_off_operation: str, \n",
      "        }\n",
      "    }\n",
      "            \n",
      "Loading database...\n",
      "Done\n",
      "Loading spectra...\n",
      "Done\n",
      "On batch 1/1\n",
      "On protein 280/280 [100%]\n",
      "Sorting the set of protein masses...\n",
      "Done\n",
      "opeating alignment for spectrum 21/1086 [2%]\n",
      "opity\n",
      "\n",
      "The matches for AGSIREAGGAFGKREKAEE: \n",
      "['TGAGSIREAGGAFGKREKAEED', 'DTGAGSIREAGGAFGKREKAEE']\n",
      "\n",
      "\n",
      "Getting rid of NOD2_E3.3820.3820.5 in taking top n alignments\n",
      "\n",
      "Creating alignment for spectrum 28/1086 [2%]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cb36b9d49bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth_run_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mtruth_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'truth_set'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFinished search. Writting results to {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/identification.py\u001b[0m in \u001b[0;36mid_spectra\u001b[0;34m(spectra_files, database_file, verbose, min_peptide_len, max_peptide_len, result_count, peak_filter, relative_abundance_filter, ppm_tolerance, precursor_tolerance, digest, missed_cleavages, cores, DEBUG, truth_set, output_dir)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mprecursor_tolerance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0mfall_off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             )\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/identification.py\u001b[0m in \u001b[0;36mid_spectrum\u001b[0;34m(spectrum, db, b_hits, y_hits, ppm_tolerance, precursor_tolerance, truth, fall_off)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mtruth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mfall_off\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfall_off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     )\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/alignment/alignment.py\u001b[0m in \u001b[0;36mattempt_alignment\u001b[0;34m(spectrum, db, b_hits, y_hits, n, ppm_tolerance, precursor_tolerance, DEBUG, is_last, truth, fall_off)\u001b[0m\n\u001b[1;32m    294\u001b[0m         p_ms = [\n\u001b[1;32m    295\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0malignment_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_in_precursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_gap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecursor_tolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         ]\n",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/alignment/alignment_utils.py\u001b[0m in \u001b[0;36mfill_in_precursor\u001b[0;34m(spectrum, sequence, db, gap, tolerance)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspectrum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecursor_mass\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtheory_precrusor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m__add_amino_acids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_off\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# subtract amino acids:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/alignment/alignment_utils.py\u001b[0m in \u001b[0;36m__add_amino_acids\u001b[0;34m(spectrum, sequence, db, gap, tolerance)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                         new_prec = gen_spectra.get_precursor(\n\u001b[1;32m    120\u001b[0m                                             \u001b[0mnew_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'('\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                                             \u001b[0mspectrum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecursor_charge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                                         )\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Layer_Research/hypedsearch/src/gen_spectra.py\u001b[0m in \u001b[0;36mget_precursor\u001b[0;34m(sequence, charge)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0mAMINO_ACIDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# proton mass is 1.00...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcharge\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPROTON_MASS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcharge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "truth_run_params = {\n",
    "    'spectra_folder': spec_file,\n",
    "    'database_file': db_file,\n",
    "    'output_dir': output_dir,\n",
    "    'min_peptide_len': minPep,\n",
    "    'max_peptide_len': maxPep,\n",
    "    'tolerance': tolerance,\n",
    "    'precursor_tolerance': precursor_tolerance,\n",
    "    'peak_filter': peak_filter, \n",
    "    'relative_abundance_filter': relative_abundance_filter,\n",
    "    'digest': 'trypsin', \n",
    "    'missed_cleavages': 2,\n",
    "    'verbose': verbose,\n",
    "    'DEBUG': False,\n",
    "    'cores': 16,\n",
    "    'truth_set': full_truth_path\n",
    "}\n",
    "\n",
    "runner.run(truth_run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load in the fall off results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_off_results = json.load(open(output_dir + 'fall_off.json'))\n",
    "len(fall_off_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run all analysis\n",
    "### Plot the raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load them into dictionaries by {type: [seq]}\n",
    "typed_fall_off = defaultdict(list)\n",
    "\n",
    "for _id, entry in fall_off_results.items():\n",
    "    typed_fall_off[entry['fall_off_operation']].append((_id, entry))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar graph it\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# get parallel x and y lists\n",
    "x = []\n",
    "y = []\n",
    "xlabels = []\n",
    "\n",
    "for i, (op, entries) in enumerate(typed_fall_off.items()):\n",
    "    x.append(i)\n",
    "    y.append(len(entries))\n",
    "    xlabels.append(op)\n",
    "    \n",
    "plt.bar(x, y, tick_label=xlabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just hybrid results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_typed_fall_off = defaultdict(list)\n",
    "nonhybrid_typed_fall_off = defaultdict(list)\n",
    "\n",
    "for _id, entry in fall_off_results.items():\n",
    "    \n",
    "    if entry['hybrid']:\n",
    "        hybrid_typed_fall_off[entry['fall_off_operation']].append((_id, entry))\n",
    "        \n",
    "    else:\n",
    "        nonhybrid_typed_fall_off[entry['fall_off_operation']].append((_id, entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar graph it\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# get parallel x and y lists\n",
    "x = []\n",
    "y = []\n",
    "xlabels = []\n",
    "\n",
    "for i, (op, entries) in enumerate(hybrid_typed_fall_off.items()):\n",
    "    x.append(i)\n",
    "    y.append(len(entries))\n",
    "    xlabels.append(op)\n",
    "    \n",
    "plt.bar(x, y, tick_label=xlabels)\n",
    "plt.title('Hybrid fall off positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar graph it\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# get parallel x and y lists\n",
    "x = []\n",
    "y = []\n",
    "xlabels = []\n",
    "\n",
    "for i, (op, entries) in enumerate(nonhybrid_typed_fall_off.items()):\n",
    "    x.append(i)\n",
    "    y.append(len(entries))\n",
    "    xlabels.append(op)\n",
    "    \n",
    "plt.bar(x, y, tick_label=xlabels)\n",
    "plt.title('Non hybrid fall off positions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_fall_offs = [x for x in hybrid_typed_fall_off['precursor_filling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pfo in precursor_fall_offs:\n",
    "    t_seq = pfo[1]['truth_sequence']\n",
    "        \n",
    "    print(f'Truth sequence: {t_seq}')\n",
    "    print('Before\\n===========================================')\n",
    "    for x in pfo[1]['meta_data']['sequences_before_precursor_filling']:\n",
    "        if x[0][:2] == t_seq[:2] and x[0][-2:] == t_seq[-2:]:\n",
    "            print(x)\n",
    "            \n",
    "    print('After\\n===========================================')\n",
    "    for x in pfo[1]['meta_data']['sequences_after_precursor_filling']:\n",
    "        if x[0][:1] == t_seq[:1] and x[0][-1:] == t_seq[-1:]:\n",
    "            print(x)\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_x_filtering = [x for x in hybrid_typed_fall_off['top_x_filtering']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close(truth, tried, ion, close_dist=2):\n",
    "    if len(tried) > len(truth):\n",
    "        return False\n",
    "    \n",
    "    if ion == 'b':\n",
    "        return truth[:close_dist].replace('I', 'B').replace('L', 'B') == tried[:close_dist].replace('I', 'B').replace('L', 'B')\n",
    "    else:\n",
    "        return truth[-close_dist:].replace('I', 'B').replace('L', 'B') == tried[-close_dist:].replace('I', 'B').replace('L', 'B')\n",
    "    \n",
    "for _id, txf in top_x_filtering:\n",
    "    t_seq = txf['truth_sequence']\n",
    "    \n",
    "    print(f'Truth sequence: {t_seq}')\n",
    "    \n",
    "    print('Kept b hits close to correct half\\n============================')\n",
    "    for x in txf['meta_data']['top_x_b_hits']:\n",
    "        if is_close(t_seq, x, 'b', 3):\n",
    "            print(x)\n",
    "\n",
    "    print('Kept y hits close to correct half\\n============================')\n",
    "    for x in txf['meta_data']['top_x_y_hits']:\n",
    "        if is_close(t_seq, x, 'y', 3):\n",
    "            print(x)\n",
    "            \n",
    "    print('Lost b hits close to correct half\\n============================')\n",
    "    for x in txf['meta_data']['excluded_b_hits']:\n",
    "        if is_close(t_seq, x, 'b', 3):\n",
    "            print(x)\n",
    "            \n",
    "    print('Lost y hits close to correct half\\n============================')\n",
    "    for x in txf['meta_data']['excluded_y_hits']:\n",
    "        if is_close(t_seq, x, 'y', 3):\n",
    "            print(x)\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non hybrid analysis\n",
    "#### Precursor filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the precursor filling subjects\n",
    "nh_precursor_fall_off = [x for x in nonhybrid_typed_fall_off['precursor_filling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through every entry and find the sequences that were closest to the real sequence as possible\n",
    "# closeness is: \n",
    "#   1. Having a lot of the right amino acids\n",
    "#   2. Not have too many amino acids or too few\n",
    "# Prioritize 1, rank by 2\n",
    "def closeness(t_seq, trying, observed_precursor, observed_precursor_charge) -> (int, int):\n",
    "    \n",
    "    from_right = 0\n",
    "    from_left = 0\n",
    "    \n",
    "    prec_distance = abs(gen_spectra.get_precursor(trying, observed_precursor_charge) - observed_precursor)\n",
    "    \n",
    "    # first check if they ARE the same\n",
    "    if t_seq == trying:\n",
    "        return (len(t_seq), 0, prec_distance)\n",
    "    \n",
    "    # go from left to right\n",
    "    i = 0\n",
    "    while i < len(t_seq) and i < len(trying) and t_seq[i] == trying[i]:\n",
    "        i += 1\n",
    "        from_left += 1\n",
    "        \n",
    "    # now right to left\n",
    "    i = -1\n",
    "    while abs(i) < len(t_seq) + 1 and abs(i) < len(trying) + 1 and t_seq[i] == trying[i]:\n",
    "        i -= 1\n",
    "        from_right += 1\n",
    "        \n",
    "    return (from_left + from_right, abs(len(t_seq) - len(trying)), prec_distance)\n",
    "\n",
    "for _id, nhpfo in nh_precursor_fall_off:\n",
    "    \n",
    "    # get the real sequence\n",
    "    t_seq = nhpfo['truth_sequence']\n",
    "    \n",
    "    # keep track of the best of the close ones \n",
    "    overlapped_idxed_close_hits = defaultdict(list)\n",
    "    \n",
    "    observed_prec = nhpfo['meta_data']['observed_precursor_mass']\n",
    "    observed_prec_charge = nhpfo['meta_data']['observed_percursor_charge']\n",
    "    \n",
    "    for non_hyb, hyb in nhpfo['meta_data']['sequences_before_precursor_filling']:\n",
    "        overlap, dist, prec_dist = closeness(t_seq, non_hyb, observed_prec, observed_prec_charge)\n",
    "        overlapped_idxed_close_hits[overlap].append((non_hyb, hyb, dist, prec_dist))\n",
    "        \n",
    "    # now get the hightest key\n",
    "    best_key = max(list(overlapped_idxed_close_hits.keys()))\n",
    "    \n",
    "    # show the best results sorted by their distance\n",
    "    print(f'({_id}) Hits with the most overlap ({best_key} AAs) for sequence {t_seq} with allowed gap {nhpfo[\"meta_data\"][\"allowed_gap\"]}')\n",
    "    print('=====================================================================================')\n",
    "    for seq, hyb_seq, dist, prec_distance in sorted(overlapped_idxed_close_hits[best_key], key=lambda x: x[2]):\n",
    "        print(f'{seq} \\t {dist} \\t {prec_distance} \\t {hyb_seq}')\n",
    "        \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the top n alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = nh_precursor_fall_off = [x for x in nonhybrid_typed_fall_off['taking_top_n_alignments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _id, top_n_spec in top_n:\n",
    "    t_seq = top_n_spec['truth_sequence']\n",
    "    \n",
    "    print(f'Top n alignments for sequence {t_seq}')\n",
    "    print('============================================================')\n",
    "    print('sequence \\t b score \\t y score \\t total score \\t precursor distance \\t hybrid')\n",
    "    print('------------------------------------------------------------')\n",
    "    [print(f'{x[\"sequence\"]} \\t {x[\"b_score\"]} \\t {x[\"y_score\"]} \\t {x[\"total_score\"]} \\t {x[\"precursor_distance\"]} \\t {\"hybrid_sequence\" in x}') for x in top_n_spec['meta_data']['top_n']]\n",
    "    \n",
    "    print('------------------------------------------------------------')\n",
    "    print('Missed alignments for this sequence')\n",
    "    print('------------------------------------------------------------')\n",
    "    [print(f'{x[\"sequence\"]} \\t {x[\"b_score\"]} \\t {x[\"y_score\"]} \\t {x[\"total_score\"]} \\t {x[\"precursor_distance\"]} \\t {\"hybrid_sequence\" in x}') for x in top_n_spec['meta_data']['not_top_n'][:10]]\n",
    "    print('------------------------------------------------------------')\n",
    "    all_alignments = [x for x in top_n_spec['meta_data']['top_n']] + [x for x in top_n_spec['meta_data']['not_top_n']]\n",
    "    num_hyb = len([0 for x in all_alignments if 'hybrid_sequence' in x])\n",
    "    p_hyb = int(100 * (float(num_hyb) / float(len(all_alignments))))\n",
    "    scores = [x['total_score'] for x in all_alignments]\n",
    "    avg_score = np.mean(scores)\n",
    "    min_score = min(scores)\n",
    "    \n",
    "    print(f'Stats: \\t Number alignments: {len(all_alignments)} \\t % hybrid: {p_hyb} \\t Average score: {avg_score} \\t min score: {min_score}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first alignment round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_as = [x for x in nonhybrid_typed_fall_off['first_alignment_round']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_aa_overlap(truth, trying):\n",
    "    overlap = 0\n",
    "    \n",
    "    if truth == trying:\n",
    "        return len(truth)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(truth) and i < len(trying) and trying[i] == truth[i]:\n",
    "        i += 1\n",
    "        overlap += 1\n",
    "        \n",
    "    i = -1\n",
    "    while i > -1 * min(len(trying), len(truth)) and truth[i] == trying[i]:\n",
    "        i -= 1\n",
    "        overlap += 1\n",
    "        \n",
    "    return overlap - max(0, len(trying) - len(truth))\n",
    "\n",
    "for _id, fa in first_as:\n",
    "    \n",
    "    t_seq = fa['truth_sequence']\n",
    "    \n",
    "    most_overlap = defaultdict(list)\n",
    "    for non_hyb, hyb in fa['meta_data']['alignments']:\n",
    "        most_overlap[most_aa_overlap(t_seq, non_hyb)].append((non_hyb, hyb))\n",
    "        \n",
    "    most_aas = max(list(most_overlap.keys()))\n",
    "    closest_matches = most_overlap[most_aas]\n",
    "    \n",
    "    \n",
    "    print(f'({_id}) Closest alignments to sequence {t_seq} at overlap {most_aas}')\n",
    "    print('=================================================================')\n",
    "    [print(f'{non_hyb} \\t {hyb}') for non_hyb, hyb in closest_matches]\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = ['SSEPTQGSYKVVIRT-PEGATE', 'SSEELLV-EAGGAFGKREKAEE', 'SSEELLVAE-GGAFGKREKAEE', 'SSEEGKLF-PEGCVVAAVAARSE', 'SSLDSGVPKRFSGS-TTAANPKE', 'STED-YQKYKFMELNLAQK', 'SVRSGTPHVAEAA-EELDPENK', 'SVRSGTPHVAEAA-EEDLPENK', 'SSLDSGVPKRFSG-LKDNATQE', 'SYKALLDSQSIPT-LECNEPK', 'SEES-YQKYKFMELNLAQK', 'SEESY-QKYKFMELNLAQK', 'SEESYQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEESY-QKYKFMELNLAQK', 'SEESYQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEES-YQKYKFMELNLAQK', 'SEESY-QKYKFMELNLAQK', 'SEESYQKYKFMELNLAQK', 'AGQVRLTYSTGE-REGILQEE', 'SSLDSGVPKRFSGSRS-PNQTE', 'QQYGVRGYPTIKF-ASYQTE', 'SSEPTQGSYKVVIRTE-PQTE', 'SSEPTQGSYKVVIRTE-PQTE', 'SESE-YQKYKFMELNLAQK', 'QQSLFQRLDF-EELDPENK', 'QQSLFQRLDF-EEDLPENK', 'STRIIYGGSVTGATC-GAPGNKPE', 'QQELPSLSVGPSLH-VATDQTE', 'SSLEKSYE-LPEATGLSPLSVE', 'SSLEKSYEL-PEATGLSPLSVE', 'SSLEKSYELPEATGLSPLSVE', 'SSLEKSYELP-EATGLSPLSVE', 'SSLEKSYELPEATGLSPLSVE', 'SSLEKSYELPEATGLSPLSVE', 'SSLEKSYE-LPEATGLSPLSVE', 'SSLEKSYEL-PEATGLSPLSVE', 'SSLEKSYELPEATGLSPLSVE', 'SSLEKSYELP-EATGLSPLSVE', 'SSLEKSYELPEATGLSPLSVE', 'SSLEKSYELPEATGLSPLSVE', 'SYDIVLVKEESLE-SGIPQTE', 'SYDIVLVKEESLEV-ASPQTE', 'SYDIVLVKEESLEV-PASQTE', 'SLVSNYLQTQE-GEAKSPGEAK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEE-YQKYKFMELNLAQK', 'SSEELQE-LPALAIYESVDDK', 'SSLDSGVPKRFSG-SLIGGNASAE', 'SSLDSGVPKRFSGS-LIGGNASAE', 'SSLDSGVPKRFSGSLIGGNASAE', 'QQYLRQEV-EKKKGDEDDK', 'SSEERAAPF-EALSRTGRSRE', 'SSEPTQGSYKVVIRTE-PDDK', 'SSEPTQGSYKVVIRTE-PDDK', 'SYGDLGGPIITT-DAATAVEQEK', 'SSQVVLPAPTGIIHQ-SEDDDK', 'SEDT-YQKYKFMELNLAQK', 'SEDT-YQKYKFMELNLAQK', 'SSEPTQGSYKVV-REGILQEE', 'STIAIVSTFTCH-TVIVEGQTE', 'AGQVRLTYSTGESN-PKVAAGTE', 'QQSLFQRLDF-AEVPEAASAE', 'STCFRPACVKLGAGAG-RPSTQE', 'QQYGVRGYPTI-EELDPENK', 'QQYGVRGYPTI-EEDLPENK', 'STCFRPACVKLG-REGILQEE', 'SSEPTQGSYKVVIRTE-PAGTE', 'SSEELQE-PLYRLNTKAASAE', 'SETD-YQKYKFMELNLAQK', 'SSEEGKLF-PRATDLTARQTE', 'SSEERAAPF-RATDLTARQTE', 'STDE-YQKYKFMELNLAQK', 'SSIPSHPSQSVR-EELDPENK', 'SSIPSHPSQSVR-EEDLPENK', 'SYDIVLVKEES-AEVPEAASAE', 'SSARFRKVDVDE-PSRETAGE', 'SEVKTDVNKIEE-VYDPKNE', 'SSIPSHPSQSVRSVN-DANPEK', 'SSLEKSYELP-EREGILQEE', 'SSLEKSYELP-EREGILQEE', 'SYDIVLVKEES-EELDPENK', 'SYDIVLVKEES-EEDLPENK', 'SLVSNYLQTQE-REGILQEE', 'QQYGVRGYPTIKF-SAYGATE', 'QQYGVRGYPTI-AEVPEAASAE', 'QTDAKKGTITIQDTGIGMTQE', 'SSEPTQGSYKVVIRTE-PTGAE', 'SSIPSHPSQSVR-AEVPEAASAE', 'SYKALLDSQSIPTD-RPSTQE', 'STRIIYGGSVTGA-EELDPENK', 'STRIIYGGSVTGA-EEDLPENK', 'SSEERAAPF-VESKHKSDFGK', 'SSEPTQGSYKVV-GEAKSPGEAK', 'SEAAKVNTD-PALAIYESVDDK', 'SSQVVLPAPTGIIH-NESESAAE']\n",
    "[x for x in ss if 'AGSIREAGGAFGKREKAEE' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
