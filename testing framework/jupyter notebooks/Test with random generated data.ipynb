{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a test of hypedsearch with generated data\n",
    "The following steps describe how the test works\n",
    "1. Load a fasta database\n",
    "2. Generate\n",
    "    1. Hybrid proteins\n",
    "    2. Peptides\n",
    "    3. Hybrid peptides from the hybrid proteins\n",
    "3. Generate spectra for all the peptides created\n",
    "4. Run hypedsearch with the .fasta file (no hybrid proteins included) and the spectra files\n",
    "5. Load the summary.json file created\n",
    "6. Determine what number of alignments were correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load fasta database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.file_io import fasta\n",
    "\n",
    "fasta_file = '../data/databases/4prots.fasta'\n",
    "database = fasta.read(fasta_file)\n",
    "database = {x['name']: x for x in database}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Generate the peptides, hybrid proteins and peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hybrid protein 0/5[0%]\r",
      "Generating hybrid protein 1/5[20%]\r",
      "Generating hybrid protein 2/5[40%]\r",
      "Generating hybrid protein 3/5[60%]\r",
      "Generating hybrid protein 4/5[80%]\r\n",
      "Finished generating hybrid proteins\n"
     ]
    }
   ],
   "source": [
    "from sequence_generation import proteins, peptides\n",
    "\n",
    "num_hybs = 5\n",
    "min_length=5\n",
    "max_length = 35\n",
    "num_peptides = 50\n",
    "\n",
    "# make hybrid proteins\n",
    "hyb_prots = proteins.generate_hybrids([x for _, x in database.items()], num_hybs, min_contribution=max_length)\n",
    "# create peptides\n",
    "non_hybrid_peps = peptides.gen_peptides([x for _, x in database.items()], num_peptides, min_length=min_length, max_length=max_length, digest='random', dist='beta')\n",
    "# create hybrid peptides\n",
    "hyb_peps = peptides.gen_peptides(hyb_prots, num_hybs, min_length=min_length, max_length=max_length, digest='random', hybrid_list=True)\n",
    "\n",
    "all_proteins_raw = [x for _,x in database.items()] + hyb_prots\n",
    "all_peptides_raw = non_hybrid_peps + hyb_peps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/testing_output/testSpectraFile.mzML'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.spectra import gen_spectra\n",
    "from src.utils import utils\n",
    "from sequence_generation import write_spectra\n",
    "\n",
    "test_directory = '../data/testing_output/'\n",
    "utils.make_dir(test_directory)\n",
    "\n",
    "spectra = []\n",
    "for pep in all_peptides_raw:\n",
    "    cont = gen_spectra.gen_spectrum(pep['sequence'])\n",
    "    spec = cont['spectrum']\n",
    "    pm = cont['precursor_mass']\n",
    "    spectra.append({'spectrum': spec, 'precursor_mass': pm})\n",
    "    \n",
    "write_spectra.write_mzml('testSpectraFile', spectra, output_dir=test_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run hypedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing spectrum 294/295[99%]\n",
      "Total runtime: 39.35865497589111 seconds\n"
     ]
    }
   ],
   "source": [
    "from src import runner\n",
    "from time import time\n",
    "\n",
    "args = {\n",
    "    'spectra_folder': test_directory,\n",
    "    'database_file': fasta_file,\n",
    "    'output_dir': test_directory\n",
    "}\n",
    "st = time()\n",
    "runner.run(args)\n",
    "print('\\nTotal runtime: {} seconds'.format(time() - st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the summary json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "summary = json.load(open(test_directory + 'summary.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Determine which number of alignments were correct\n",
    "This needs to be broken down into hybrid and non hybrid peptides to get some stats on how well its doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
