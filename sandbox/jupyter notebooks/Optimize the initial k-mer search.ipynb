{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the initial k-mer search\n",
    "right now we are doing 8000 comparisons for EACH spectrum in the observed to filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.objects import Spectrum, BasicScoredKmer, Kmer\n",
    "from src.database import Database\n",
    "from src.scoring import scoring\n",
    "from src.spectra.gen_spectra import gen_spectrum\n",
    "from src.file_io import fasta\n",
    "from src.identfication import filtering\n",
    "\n",
    "from modules.sequence_generation import proteins, peptides\n",
    "\n",
    "from collections import namedtuple, defaultdict\n",
    "from bisect import bisect, bisect_right\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current method (26 May 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interesting_kmers(spectrum: Spectrum, mers: list) -> list:\n",
    "    '''\n",
    "    Go through a list of mers and find the ones that are considered interesting\n",
    "\n",
    "    Inputs:\n",
    "        spectrum:   Spectrum namedtuple instance\n",
    "        mers:       list of strings containing kmers\n",
    "    Outputs:\n",
    "        (b_anchors, y_anchors): list of BasicScoredKmer namedtuple instances\n",
    "    '''\n",
    "    # for ever mer, score the subsequence\n",
    "    mer_scores = []\n",
    "    for mer in mers:\n",
    "        b_score, y_score = scoring.score_subsequence(spectrum.spectrum, mer)\n",
    "        bsk = BasicScoredKmer(b_score, y_score, mer)\n",
    "        mer_scores.append(bsk)\n",
    "    b_anchors = filtering.score_filter(mer_scores, 'b_score')\n",
    "    y_anchors = filtering.score_filter(mer_scores, 'y_score')\n",
    "    return (b_anchors, y_anchors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary search on tuples\n",
    "Build a list for all 3-mers that is of the form\n",
    "```python\n",
    "all3mers = [(reference_mass, protein, starting_position), ... ]\n",
    "\n",
    "for observed in spectra:\n",
    "    for mass in observed:\n",
    "        i = binarysearch(mass - error, all3mers)\n",
    "        hits = []\n",
    "        for j in range(i, inf):\n",
    "            if all3mers[i + j][0] <= mass + error:\n",
    "                hits.append(all3mers[i + j]\n",
    "            else break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MassSequence = namedtuple('MassSequence', ['mass', 'sequence'])\n",
    "\n",
    "def ppm_opt(observed: float, ppm_tolerance: float) -> float:\n",
    "    '''\n",
    "    Calculate the ppm tolerance\n",
    "    '''\n",
    "    return abs((ppm_tolerance / 1000000)*observed)\n",
    "\n",
    "def make_all_base_mers(database: Database, base_mer: int) -> list:\n",
    "    '''\n",
    "    Create the list of all the base mers from 1 to base_mer with mass, protein, start position information\n",
    "    \n",
    "    Inputs:\n",
    "        database:    (Database) source of the sequences\n",
    "        base_mer:    (int) the base k-mer to make up to\n",
    "    Outputs:\n",
    "        list of MassSequence for all singly, doubly b and y masses\n",
    "    '''\n",
    "    allbasemers = []\n",
    "    database.set_kmer_size(base_mer)\n",
    "    database.index()\n",
    "    md = database.metadata\n",
    "    for mer in md:\n",
    "        mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        for mass in mer_spec:\n",
    "            allbasemers.append(MassSequence(mass, mer))\n",
    "        \n",
    "    allbasemers.sort(key=lambda x: x.mass)\n",
    "    return allbasemers\n",
    "\n",
    "def seach_base_kmers(observed: Spectrum, allbasemers: list, tolerance: float) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        database:    (Database) source of the sequences\n",
    "        allbasemers: (list of MassSequence) all of the basemers made from the function 'make_all_base_mers'\n",
    "        tolerance:   (float) the ppm tolerance to allow\n",
    "        base_mer:    (int) length of the base kmer\n",
    "    Outputs:\n",
    "        list of kmer strings\n",
    "    '''\n",
    "    hits = []\n",
    "    allbasemermasses = [x.mass for x in allbasemers]\n",
    "    for mass in observed.spectrum:\n",
    "        tol = ppm_opt(mass, tolerance)\n",
    "        lb_mass = mass - tol\n",
    "        ub_mass = mass + tol\n",
    "        start_hit_index = bisect(allbasemermasses, lb_mass)\n",
    "        for i in range(start_hit_index, len(allbasemers)):\n",
    "            if allbasemers[i].mass <= ub_mass:\n",
    "                hits.append(allbasemers[i].sequence)\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "    return hits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary hashing with binary search\n",
    "Use the same technique as the last attempt, but instead of a pure binary search, do a binary search on a smaller list that you hash into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_base_mers_hash_bs(database: Database, base_mer: int) -> defaultdict:\n",
    "    '''\n",
    "    Create the list of all the base mers from 1 to base_mer with mass, protein, start position information\n",
    "    \n",
    "    Inputs:\n",
    "        database:    (Database) source of the sequences\n",
    "        base_mer:    (int) the base k-mer to make up to\n",
    "    Outputs:\n",
    "        list of MassSequence for all singly, doubly b and y masses\n",
    "    '''\n",
    "    allbasemers = defaultdict(list)\n",
    "    database.set_kmer_size(base_mer)\n",
    "    database.index()\n",
    "    md = database.metadata\n",
    "    for mer in md:\n",
    "        mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        rev_mer = mer[::-1]\n",
    "        rev_mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        for mass in mer_spec:\n",
    "            mass_key = math.floor(mass)\n",
    "            allbasemers[mass_key].append(MassSequence(mass, mer))\n",
    "\n",
    "    for _, massseqlists in allbasemers.items():\n",
    "        massseqlists.sort(key=lambda x: x.mass)\n",
    "    return allbasemers\n",
    "\n",
    "def seach_base_kmers_hash_bs(observed: Spectrum, allbasemers: dict, tolerance: float) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        allbasemers: (dict of list of MassSequence) all of the basemers made from the function 'make_all_base_mers_hash'\n",
    "        tolerance:   (float) the ppm tolerance to accept for each mass\n",
    "    Outputs:\n",
    "        list of MassSequence for all masses that were in the acceptable range of an observed mass\n",
    "    '''\n",
    "    hits = []\n",
    "    for mass in observed.spectrum:\n",
    "        tol = ppm_opt(mass, tolerance)\n",
    "        lb_mass = mass - tol\n",
    "        ub_mass = mass + tol\n",
    "        lb_mass_key = math.floor(lb_mass)\n",
    "        ub_mass_key = math.floor(ub_mass)\n",
    "        \n",
    "        lb_list = allbasemers[lb_mass_key]\n",
    "        hitstartindex = bisect([x.mass for x in lb_list], lb_mass)\n",
    "        hits += [lb_list[i].sequence for i in range(hitstartindex, len(lb_list)) if lb_mass <= lb_list[i].mass <= ub_mass]\n",
    "        if lb_mass_key != ub_mass_key:\n",
    "            ub_list = allbasemers[ub_mass_key]\n",
    "            hitendindex = bisect_right([x.mass for x in ub_list], ub_mass)\n",
    "            hits += [ub_list[i].sequence for i in range(0, hitendindex) if lb_mass <= ub_list[i].mass <= ub_mass]\n",
    "            \n",
    "    return hits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary hashing without binary search\n",
    "Use the same technique as the last attempt, but instead of a pure binary search, do a binary search on a smaller list that you hash into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_base_mers_hash(database: Database, base_mer: int) -> defaultdict:\n",
    "    '''\n",
    "    Create the list of all the base mers from 1 to base_mer with mass, protein, start position information\n",
    "    \n",
    "    Inputs:\n",
    "        database:    (Database) source of the sequences\n",
    "        base_mer:    (int) the base k-mer to make up to\n",
    "    Outputs:\n",
    "        list of MassSequence for all singly, doubly b and y masses\n",
    "    '''\n",
    "    allbasemers = defaultdict(list)\n",
    "    database.set_kmer_size(base_mer)\n",
    "    database.index()\n",
    "    md = database.metadata\n",
    "    for mer in md:\n",
    "        mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        rev_mer = mer[::-1]\n",
    "        rev_mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        for mass in mer_spec:\n",
    "            mass_key = math.floor(mass)\n",
    "            allbasemers[mass_key].append(MassSequence(mass, mer))\n",
    "\n",
    "    return allbasemers\n",
    "\n",
    "def seach_base_kmers_hash(observed: Spectrum, allbasemers: dict, tolerance: float) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        allbasemers: (dict of list of MassSequence) all of the basemers made from the function 'make_all_base_mers_hash'\n",
    "        tolerance:   (float) the ppm tolerance to accept for each mass\n",
    "    Outputs:\n",
    "        list of MassSequence for all masses that were in the acceptable range of an observed mass\n",
    "    '''\n",
    "    hits = []\n",
    "    for mass in observed.spectrum:\n",
    "        tol = ppm_opt(mass, tolerance)\n",
    "        lb_mass = mass - tol\n",
    "        ub_mass = mass + tol\n",
    "        lb_mass_key = math.floor(lb_mass)\n",
    "        ub_mass_key = math.floor(ub_mass)\n",
    "        \n",
    "        hits += [x.sequence for x in allbasemers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "        if lb_mass_key != ub_mass_key:\n",
    "            hits += [x.sequence for x in allbasemers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "            \n",
    "    return hits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run these and test the time\n",
    "So we need to be fair here. What we'll do is the following:\n",
    "1. Include any setup time thats necessary (nothing that they both need)\n",
    "2. Run it on different numbers of observed spectrum and database lengths to see how well they do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for both\n",
    "#### 1. Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastafile = '../../testing framework/data/databases/100prots.fasta'\n",
    "db = Database(fastafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = fasta.read(fastafile, True)\n",
    "\n",
    "database = {x['name']: x for x in database}\n",
    "\n",
    "num_hybs = 5\n",
    "min_length= 5\n",
    "max_length = 35\n",
    "num_peptides = 1000\n",
    "min_cont = 3 #min contribution for each side of a hybrid\n",
    "\n",
    "# create peptides\n",
    "non_hybrid_peps = peptides.gen_peptides([x for _, x in database.items()], num_peptides, min_length=min_length, max_length=max_length, digest='random', dist='beta')\n",
    "# create hybrid peptides\n",
    "\n",
    "all_proteins_raw = [x for _,x in database.items()]\n",
    "all_peptides_raw = non_hybrid_peps \n",
    "\n",
    "peps = {}\n",
    "for i, pep in enumerate(all_peptides_raw):\n",
    "    peps[i] = pep\n",
    "    peps[i]['scan_no'] = i\n",
    "\n",
    "spectra = []\n",
    "sorted_keys = [int(c) for c in peps.keys()]\n",
    "sorted_keys.sort()\n",
    "for k in sorted_keys:\n",
    "    pep = peps[k]\n",
    "    cont = gen_spectrum(pep['sequence'])\n",
    "    spec = cont['spectrum']\n",
    "    pm = cont['precursor_mass']\n",
    "    spectra.append({'spectrum': spec, 'precursor_mass': pm})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for the old method: 396.88234782218933\n"
     ]
    }
   ],
   "source": [
    "old_st = time.time()\n",
    "db.index()\n",
    "md = db.metadata\n",
    "mers = list(md.keys())\n",
    "speclen = len(spectra)\n",
    "old_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    old_res_dict[i] = find_interesting_kmers(s, mers)\n",
    "print('\\ntotal time for the old method: {}'.format(time.time() - old_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for the binary search on large list method: 19.75441598892212\n"
     ]
    }
   ],
   "source": [
    "bs_st = time.time()\n",
    "all3mers = make_all_base_mers(db, 3)\n",
    "speclen = len(spectra)\n",
    "bs_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    bs_res_dict[i] = seach_base_kmers(s, all3mers, 20)\n",
    "print('\\ntotal time for the binary search on large list method: {}'.format(time.time() - bs_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for the binary search on top of hash: 3.712261915206909\n"
     ]
    }
   ],
   "source": [
    "bsh_st = time.time()\n",
    "all3mers = make_all_base_mers_hash_bs(db, 3)\n",
    "speclen = len(spectra)\n",
    "bsh_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    bsh_res_dict[i] = seach_base_kmers_hash_bs(s, all3mers, 20)\n",
    "#     bsh_res_dict[i] += search_base_kmers_hash(s, all3mersrev, 0.05)\n",
    "print('\\ntotal time for the binary search on top of hash: {}'.format(time.time() - bsh_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for pure hash method: 3.9834797382354736\n"
     ]
    }
   ],
   "source": [
    "hs_st = time.time()\n",
    "all3mers = make_all_base_mers_hash(db, 3)\n",
    "speclen = len(spectra)\n",
    "hs_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    hs_res_dict[i] = seach_base_kmers_hash(s, all3mers, 20)\n",
    "#     bsh_res_dict[i] += search_base_kmers_hash(s, all3mersrev, 0.05)\n",
    "print('\\ntotal time for pure hash method: {}'.format(time.time() - hs_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results (for now just the hash and the binary one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking elements 5999/6000\r"
     ]
    }
   ],
   "source": [
    "check_len = len(bsh_res_dict)\n",
    "for i in range(len(bsh_res_dict)):\n",
    "    print('checking elements {}/{}\\r'.format(i, check_len), end='')\n",
    "    if not all([x in bs_res_dict[i] for x in bsh_res_dict[i]]):\n",
    "        print(f'NOT EQUAL AT {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results (hash and binary hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking elements 5999/6000\r"
     ]
    }
   ],
   "source": [
    "check_len = len(hs_res_dict)\n",
    "for i in range(len(hs_res_dict)):\n",
    "    print('checking elements {}/{}\\r'.format(i, check_len), end='')\n",
    "    if not all([x in hs_res_dict[i] for x in bsh_res_dict[i]]):\n",
    "        print(f'NOT EQUAL AT {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results (hash to the old one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking elements 999/1000\r"
     ]
    }
   ],
   "source": [
    "check_len = len(old_res_dict)\n",
    "for i in range(len(old_res_dict)):\n",
    "    total_results = [x.kmer for x in old_res_dict[i][0]] + [x.kmer for x in old_res_dict[i][1]]\n",
    "    print('checking elements {}/{}\\r'.format(i, check_len), end='')\n",
    "    if not all([x in total_results for x in hs_res_dict[i]]):\n",
    "        print(f'NOT EQUAL AT {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871\n",
      "871\n"
     ]
    }
   ],
   "source": [
    "print(len(list(set([x.kmer for x in old_res_dict[0][0]] + [x.kmer for x in old_res_dict[0][1]]))))\n",
    "print(len(list(set(bsh_res_dict[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
