{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the initial k-mer search\n",
    "right now we are doing 8000 comparisons for EACH spectrum in the observed to filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.types.objects import Spectrum, BasicScoredKmer, Kmer\n",
    "from src.types.database import Database\n",
    "from src.scoring import scoring\n",
    "from src.spectra.gen_spectra import gen_spectrum\n",
    "from src.file_io import fasta\n",
    "from src.identfication import filtering\n",
    "\n",
    "from modules.sequence_generation import proteins, peptides\n",
    "\n",
    "from collections import namedtuple, defaultdict\n",
    "from bisect import bisect\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current method (26 May 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interesting_kmers(spectrum: Spectrum, mers: list) -> (list, list):\n",
    "    '''\n",
    "    Go through a list of mers and find the ones that are considered interesting\n",
    "\n",
    "    Inputs:\n",
    "        spectrum:   Spectrum namedtuple instance\n",
    "        mers:       list of strings containing kmers\n",
    "    Outputs:\n",
    "        (b_anchors, y_anchors): list of BasicScoredKmer namedtuple instances\n",
    "    '''\n",
    "    # for ever mer, score the subsequence\n",
    "    mer_scores = []\n",
    "    for mer in mers:\n",
    "        b_score, y_score = scoring.score_subsequence(spectrum.spectrum, mer)\n",
    "        bsk = BasicScoredKmer(b_score, y_score, mer)\n",
    "        mer_scores.append(bsk)\n",
    "    b_anchors = filtering.score_filter(mer_scores, 'b_score')\n",
    "    y_anchors = filtering.score_filter(mer_scores, 'y_score')\n",
    "    return (b_anchors, y_anchors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary search on tuples\n",
    "Build a list for all 3-mers that is of the form\n",
    "```python\n",
    "all3mers = [(reference_mass, protein, starting_position), ... ]\n",
    "\n",
    "for observed in spectra:\n",
    "    for mass in observed:\n",
    "        i = binarysearch(mass - error, all3mers)\n",
    "        hits = []\n",
    "        for j in range(i, inf):\n",
    "            if all3mers[i + j][0] <= mass + error:\n",
    "                hits.append(all3mers[i + j]\n",
    "            else break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MassSequence = namedtuple('MassSequence', ['mass', 'protein', 'start_position'])\n",
    "\n",
    "def make_all_base_mers(database: Database, base_mer: int) -> list:\n",
    "    '''\n",
    "    Create the list of all the base mers from 1 to base_mer with mass, protein, start position information\n",
    "    \n",
    "    Inputs:\n",
    "        database:    (Database) source of the sequences\n",
    "        base_mer:    (int) the base k-mer to make up to\n",
    "    Outputs:\n",
    "        list of MassSequence for all singly, doubly b and y masses\n",
    "    '''\n",
    "    allbasemers = []\n",
    "    database.set_kmer_size(base_mer)\n",
    "    database.index()\n",
    "    md = database.metadata\n",
    "    for mer, lokmers in md.items():\n",
    "        mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        for kmer in lokmers:\n",
    "            for mass in mer_spec:\n",
    "                allbasemers.append(MassSequence(mass, kmer.protein, kmer.start_position))\n",
    "    allbasemers.sort(key=lambda x: x.mass)\n",
    "    return allbasemers\n",
    "\n",
    "def seach_base_kmers(observed: Spectrum, database: Database, allbasemers: list, tolerance: float, base_mer: int) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        database:    (Database) source of the sequences\n",
    "        allbasemers: (list of MassSequence) all of the basemers made from the function 'make_all_base_mers'\n",
    "        tolerance:   (float) the tolerance in Da to accept\n",
    "        base_mer:    (int) length of the base kmer\n",
    "    Outputs:\n",
    "        list of kmer strings\n",
    "    '''\n",
    "    hits = []\n",
    "    allbasemermasses = [x.mass for x in allbasemers]\n",
    "    for mass in observed.spectrum:\n",
    "        lb_mass = mass - tolerance\n",
    "        ub_mass = mass + tolerance\n",
    "        start_hit_index = bisect(allbasemermasses, lb_mass)\n",
    "        for i in range(start_hit_index, len(allbasemers)):\n",
    "            if allbasemers[i].mass <= ub_mass:\n",
    "                hits.append(allbasemers[i])\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "    # so here we want to take ALL of the hits (since they are non-zero) and make base_mers out of them\n",
    "    mers = {} # used for fast indexing to see if the mer is already found\n",
    "    for hit in hits:\n",
    "        merseq = database.get_entry_by_name(hit.protein).sequence[hit.start_position: hit.start_position + base_mer]\n",
    "        mers[merseq] = 1\n",
    "    return list(mers.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary hashing with binary search\n",
    "Use the same technique as the last attempt, but instead of a pure binary search, do a binary search on a smaller list that you hash into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_base_mers_hash(database: Database, base_mer: int) -> defaultdict:\n",
    "    '''\n",
    "    Create the list of all the base mers from 1 to base_mer with mass, protein, start position information\n",
    "    \n",
    "    Inputs:\n",
    "        database:    (Database) source of the sequences\n",
    "        base_mer:    (int) the base k-mer to make up to\n",
    "    Outputs:\n",
    "        list of MassSequence for all singly, doubly b and y masses\n",
    "    '''\n",
    "    allbasemers = defaultdict(list)\n",
    "    database.set_kmer_size(base_mer)\n",
    "    database.index()\n",
    "    md = database.metadata\n",
    "    for mer, lokmers in md.items():\n",
    "        mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        for kmer in lokmers:\n",
    "            for mass in mer_spec:\n",
    "                mass_key = math.floor(mass)\n",
    "                if mass_key not in allbasemers:\n",
    "                    allbasemers[mass_key] = []\n",
    "                allbasemers[mass_key].append(MassSequence(mass, kmer.protein, kmer.start_position))\n",
    "    return allbasemers\n",
    "\n",
    "def seach_base_kmers_hash(observed: Spectrum, database: Database, allbasemers: dict, tolerance: float, base_mer: int) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        allbasemers: (dict of list of MassSequence) all of the basemers made from the function 'make_all_base_mers_hash'\n",
    "        tolerance:   (float) the tolerance in Da to accept\n",
    "    Outputs:\n",
    "        list of MassSequence for all masses that were in the acceptable range of an observed mass\n",
    "    '''\n",
    "    hits = []\n",
    "    for mass in observed.spectrum:\n",
    "        lb_mass = mass - tolerance\n",
    "        ub_mass = mass + tolerance\n",
    "        lb_mass_key = math.floor(lb_mass)\n",
    "        ub_mass_key = math.floor(ub_mass)\n",
    "        \n",
    "        hits += [x for x in allbasemers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "        if lb_mass_key != ub_mass_key:\n",
    "            hits += [x for x in allbasemers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "            \n",
    "    # so here we want to take ALL of the hits (since they are non-zero) and make base_mers out of them\n",
    "    mers = {} # used for fast indexing to see if the mer is already found\n",
    "    for hit in hits:\n",
    "        merseq = database.get_entry_by_name(hit.protein).sequence[hit.start_position: hit.start_position + base_mer]\n",
    "        mers[merseq] = 1\n",
    "    return list(mers.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run these and test the time\n",
    "So we need to be fair here. What we'll do is the following:\n",
    "1. Include any setup time thats necessary (nothing that they both need)\n",
    "2. Run it on different numbers of observed spectrum and database lengths to see how well they do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for both\n",
    "#### 1. Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastafile = '../../testing framework/data/databases/100prots.fasta'\n",
    "db = Database(fastafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = fasta.read(fastafile, True)\n",
    "\n",
    "database = {x['name']: x for x in database}\n",
    "\n",
    "num_hybs = 5\n",
    "min_length= 5\n",
    "max_length = 35\n",
    "num_peptides = 1000\n",
    "min_cont = 3 #min contribution for each side of a hybrid\n",
    "\n",
    "# create peptides\n",
    "non_hybrid_peps = peptides.gen_peptides([x for _, x in database.items()], num_peptides, min_length=min_length, max_length=max_length, digest='random', dist='beta')\n",
    "# create hybrid peptides\n",
    "\n",
    "all_proteins_raw = [x for _,x in database.items()]\n",
    "all_peptides_raw = non_hybrid_peps \n",
    "\n",
    "peps = {}\n",
    "for i, pep in enumerate(all_peptides_raw):\n",
    "    peps[i] = pep\n",
    "    peps[i]['scan_no'] = i\n",
    "\n",
    "spectra = []\n",
    "sorted_keys = [int(c) for c in peps.keys()]\n",
    "sorted_keys.sort()\n",
    "for k in sorted_keys:\n",
    "    pep = peps[k]\n",
    "    cont = gen_spectrum(pep['sequence'])\n",
    "    spec = cont['spectrum']\n",
    "    pm = cont['precursor_mass']\n",
    "    spectra.append({'spectrum': spec, 'precursor_mass': pm})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for the old method: 406.42886781692505\n"
     ]
    }
   ],
   "source": [
    "old_st = time.time()\n",
    "db.index()\n",
    "md = db.metadata\n",
    "mers = list(md.keys())\n",
    "speclen = len(spectra)\n",
    "old_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    old_res_dict[i] = find_interesting_kmers(s, mers)\n",
    "print('\\ntotal time for the old method: {}'.format(time.time() - old_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for the binary search on large list method: 170.562105178833\n"
     ]
    }
   ],
   "source": [
    "bs_st = time.time()\n",
    "all3mers = make_all_base_mers(db, 3)\n",
    "speclen = len(spectra)\n",
    "bs_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    bs_res_dict[i] = seach_base_kmers(s, db, all3mers, 0.05, 3)\n",
    "print('\\ntotal time for the binary search on large list method: {}'.format(time.time() - bs_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7487 unique kmers\n",
      "spectrum 999/1000\n",
      "total time for the binary search on large list method: 57.76775813102722\n"
     ]
    }
   ],
   "source": [
    "bsh_st = time.time()\n",
    "all3mers = make_all_base_mers_hash(db, 3)\n",
    "speclen = len(spectra)\n",
    "bsh_res_dict = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    bsh_res_dict[i] = seach_base_kmers_hash(s, db, all3mers, 0.05, 3)\n",
    "print('\\ntotal time for the binary search on large list method: {}'.format(time.time() - bsh_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results (for now just the hash and the binary one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking elements 13/1000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0b5a81f72d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsh_res_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checking elements {}/{}\\r'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbs_res_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbsh_res_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'NOT EQUAL AT {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0b5a81f72d83>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsh_res_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checking elements {}/{}\\r'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbs_res_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbsh_res_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'NOT EQUAL AT {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check_len = len(bsh_res_dict)\n",
    "for i in range(len(bsh_res_dict)):\n",
    "    print('checking elements {}/{}\\r'.format(i, check_len), end='')\n",
    "    if not any([x in bs_res_dict[i] for x in bsh_res_dict[i]]):\n",
    "        print(f'NOT EQUAL AT {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
