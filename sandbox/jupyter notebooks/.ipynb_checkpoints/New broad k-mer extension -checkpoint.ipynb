{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New k-mer extension that happens more globally\n",
    "Make it run faster.\n",
    "\n",
    "Steps:\n",
    "1. Index the database \n",
    "2. Build a hash table of the masses of all b+, b++, y+, and y++ ions and masses\n",
    "3. Search for all sequences that get mass hits\n",
    "4. Filter the results\n",
    "5. Attempt aligments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: latin-1 -*-\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.types.database import Database\n",
    "from src.types.objects import Spectrum\n",
    "from src.file_io import fasta\n",
    "from modules.sequence_generation import proteins, peptides\n",
    "from src.spectra.gen_spectra import gen_spectrum\n",
    "from src.scoring.scoring import score_subsequence\n",
    "\n",
    "import math\n",
    "from collections import namedtuple, defaultdict\n",
    "import time\n",
    "import bisect\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global extension and addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MassSequence = namedtuple('MassSequence', ['mass', 'sequence'])\n",
    "\n",
    "def ppm_to_da(reference: float, ppm_tolerance: float) -> float:\n",
    "    '''\n",
    "    Calculate the ppm difference between the observed and actual\n",
    "    '''\n",
    "    return abs((ppm_tolerance / 1000000)*reference)\n",
    "\n",
    "\n",
    "def search_kmers_hash(observed: Spectrum, kmers: dict, tolerance: float) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        allbasemers: (dict of list of MassSequence) all of the basemers made from the function 'make_all_base_mers_hash'\n",
    "        tolerance:   (float) the ppm tolerance to accept for each mass\n",
    "    Outputs:\n",
    "        list of MassSequence for all masses that were in the acceptable range of an observed mass\n",
    "    '''\n",
    "    hits = []\n",
    "    for mass in observed.spectrum:\n",
    "        tol = ppm_to_da(mass, tolerance)\n",
    "        lb_mass = mass - tol\n",
    "        ub_mass = mass + tol\n",
    "        lb_mass_key = math.floor(lb_mass)\n",
    "        ub_mass_key = math.floor(ub_mass)\n",
    "        hits += [x.sequence for x in kmers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "        if lb_mass_key != ub_mass_key:\n",
    "            hits += [x.sequence for x in kmers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "            \n",
    "    return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a dictionary for sizes min length to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "KmerMasses = namedtuple('KmerMasses', ['bs', 'bd', 'ys', 'yd'])\n",
    "\n",
    "def build_kmer_mass_dicts(database: Database, min_peptide_len: int, max_peptide_len: int) -> KmerMasses:\n",
    "    '''\n",
    "    '''\n",
    "    bs = defaultdict(list)\n",
    "    bd = defaultdict(list)\n",
    "    ys = defaultdict(list)\n",
    "    yd = defaultdict(list)\n",
    "    \n",
    "    kmer_tracker = {}\n",
    "    \n",
    "    print(f'Indexing database for k={max_peptide_len}...')\n",
    "    database.set_kmer_size(max_peptide_len)\n",
    "    database.index()\n",
    "    print('Done')\n",
    "    mdl = len(database.metadata.keys())\n",
    "    \n",
    "    printskiplen = mdl // 1000\n",
    "    printskipc = 0\n",
    "    \n",
    "    for i, kmer in enumerate(list(database.metadata.keys())):\n",
    "        if len(kmer) < min_peptide_len: \n",
    "            continue\n",
    "            \n",
    "        if printskipc == printskiplen:\n",
    "            print(f'Looking at kmer {i + 1}/{mdl}\\r', end='')\n",
    "            printskipc = 0\n",
    "            \n",
    "        printskipc += 1\n",
    "        \n",
    "        endindex = min(len(kmer), max_peptide_len)\n",
    "        for i in range(min_peptide_len, endindex+1):\n",
    "            subseq = kmer[:i]\n",
    "            \n",
    "            if subseq in kmer_tracker:\n",
    "                continue\n",
    "                \n",
    "            kmer_tracker[subseq] = None # none takes up very little memory\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='b', charge=1)['spectrum'])\n",
    "            bs[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='b', charge=2)['spectrum'])\n",
    "            bd[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='y', charge=1)['spectrum'])\n",
    "            ys[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='y', charge=2)['spectrum'])\n",
    "            yd[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "        \n",
    "    del kmer_tracker\n",
    "        \n",
    "    return KmerMasses(bs, bd, ys, yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an alignment from the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_overlaps(seq1: str, seq2: str) -> str:\n",
    "    '''\n",
    "    '''\n",
    "    alignment = None\n",
    "    # if we have a perfect overlap, return it\n",
    "    if seq1 == seq2:\n",
    "        alignment = seq1\n",
    "    \n",
    "    # if one is a full subsequence of another, return the larger one\n",
    "    elif seq1 in seq2:\n",
    "        alignment = seq2\n",
    "    elif seq2 in seq1:\n",
    "        alignment = seq1\n",
    "    \n",
    "    else:\n",
    "        # try and find an alignment. seq2 should overlap as much of the right of seq1 as possible\n",
    "        start_points = [i for i in range(len(seq1)) if seq2[0] == seq1[i]]\n",
    "        for sp in start_points:\n",
    "            # try and see if extending it makes it match\n",
    "            for i in range(sp, len(seq1)):\n",
    "                if seq1[i] != seq2[i-sp]:\n",
    "                    break\n",
    "            if i == len(seq1) - 1:\n",
    "                s2_start = len(seq1) - sp\n",
    "                right_seq = seq2[s2_start] if s2_start < len(seq2) else ''\n",
    "                alignment = seq1 + seq2[s2_start:]\n",
    "    \n",
    "    return alignment\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load fasta database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = '../../testing framework/data/databases/500prots.fasta'\n",
    "database = fasta.read(fasta_file, True)\n",
    "\n",
    "database = {x['name']: x for x in database}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Generate the peptides, hybrid proteins and peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hybrid protein 0/5[0%]\r",
      "Generating hybrid protein 1/5[20%]\r",
      "Generating hybrid protein 2/5[40%]\r",
      "Generating hybrid protein 3/5[60%]\r",
      "Generating hybrid protein 4/5[80%]\r\n",
      "Finished generating hybrid proteins\n",
      "EVP-IKS\n"
     ]
    }
   ],
   "source": [
    "test_directory = '../../testing framework/data/testing_output/'\n",
    "\n",
    "num_hybs = 5\n",
    "min_length= 5\n",
    "max_length = 35\n",
    "num_peptides = 100\n",
    "min_cont = 3 #min contribution for each side of a hybrid\n",
    "\n",
    "# make hybrid proteins\n",
    "hyb_prots = proteins.generate_hybrids([x for _, x in database.items()], num_hybs, min_contribution=max_length)\n",
    "# create peptides\n",
    "non_hybrid_peps = peptides.gen_peptides([x for _, x in database.items()], num_peptides, min_length=min_length, max_length=max_length, digest='random', dist='beta')\n",
    "# create hybrid peptides\n",
    "hyb_peps = peptides.gen_peptides(hyb_prots, num_hybs, min_length=min_length, max_length=max_length, digest='random', min_contribution=min_cont, hybrid_list=True)\n",
    "print(hyb_peps[0]['hybrid_sequence'])\n",
    "all_proteins_raw = [x for _,x in database.items()] + hyb_prots\n",
    "all_peptides_raw = non_hybrid_peps + hyb_peps\n",
    "\n",
    "peps = {}\n",
    "for i, pep in enumerate(all_peptides_raw):\n",
    "    peps[i] = pep\n",
    "    peps[i]['scan_no'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = []\n",
    "sorted_keys = [int(c) for c in peps.keys()]\n",
    "sorted_keys.sort()\n",
    "for k in sorted_keys:\n",
    "    pep = peps[k]\n",
    "    cont = gen_spectrum(pep['sequence'])\n",
    "    spec = cont['spectrum']\n",
    "    pm = cont['precursor_mass']\n",
    "    spectra.append({'spectrum': spec, 'precursor_mass': pm})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the new kmer extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the kmer hash table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database...\n",
      "Done.g protein 496/500 to tree\n",
      "Building hashes for kmers...\n",
      "Indexing database for k=35...\n",
      "Done\n",
      "Looking at kmer 295856/295859\n",
      "Done. Time to complete: 518.3996231555939\n"
     ]
    }
   ],
   "source": [
    "indexing_st = time.time()\n",
    "\n",
    "print('Loading database...')\n",
    "db = Database(fasta_file)\n",
    "print('Done.')\n",
    "\n",
    "print('Building hashes for kmers...')\n",
    "kmermasses = build_kmer_mass_dicts(db, min_cont, max_length)\n",
    "print(f'\\nDone. Time to complete: {time.time() - indexing_st}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On spectrum 345/345\n",
      "Done. Time to complete: 477.38s\n",
      "Time breakdown:         \n",
      "hash search time: 210.38s,\t 44%         \n",
      "results filtering time: 263.54s, \t 55%         \n",
      "alignment time: 3.35s, \t0%\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "hashsearchtime = 0\n",
    "alignmenttime = 0\n",
    "resultfilteringtime = 0\n",
    "\n",
    "speclen = len(spectra)\n",
    "alignments = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('On spectrum {}/{}\\r'.format(i + 1, speclen), end='')\n",
    "    hstst = time.time()\n",
    "    # find all of the basic hits first\n",
    "    s = Spectrum(spec['spectrum'])\n",
    "    bs, bd, ys, yd = search_kmers_hash(s, kmermasses.bs, 20), search_kmers_hash(s, kmermasses.bd, 20), search_kmers_hash(s, kmermasses.ys, 20), search_kmers_hash(s, kmermasses.yd, 20)\n",
    "    results = {\n",
    "        'bs': bs,\n",
    "        'bd': bd,\n",
    "        'ys': ys,\n",
    "        'yd': yd,\n",
    "    }\n",
    "    hashsearchtime += (time.time() - hstst)\n",
    "    #########################################################################\n",
    "    #                      BIGGEST TIME TAKER BLOCK\n",
    "    #########################################################################\n",
    "    rftst = time.time()\n",
    "    # narrow down the results to a few promising kmers\n",
    "    basemerhashedb = defaultdict(list)\n",
    "    basemerhashedy = defaultdict(list)\n",
    "    b_scores = []\n",
    "    y_scores = []\n",
    "    # hash by the base mer (in this case its 3)\n",
    "    for key, value in results.items():\n",
    "        if 'b' in key:\n",
    "            for val in value:\n",
    "                basemerb = val[:3]\n",
    "                if basemerb not in basemerhashedb:\n",
    "                    b_scores.append((basemerb, score_subsequence(s.spectrum, basemerb)[0]))\n",
    "                basemerhashedb[basemerb].append(val)\n",
    "        else:\n",
    "            for val in value:\n",
    "                basemery = val[len(val)-3:]\n",
    "                if basemery not in basemerhashedy:\n",
    "                    y_scores.append((basemery, score_subsequence(s.spectrum, basemery)[1]))\n",
    "                basemerhashedy[basemery].append(val)\n",
    "        \n",
    "    # sort by the score of the kmers\n",
    "#     b_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "#     y_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    toscoreb = []\n",
    "    toscorey = []\n",
    "    for basemerb in sorted(b_scores, key=itemgetter(1), reverse=True)[:5]:\n",
    "        toscoreb += [basemerb[0]] + basemerhashedb[basemerb[0]]\n",
    "        \n",
    "    for basemery in sorted(y_scores, key=itemgetter(1), reverse=True)[:5]:\n",
    "        toscorey += [basemery[0]] + basemerhashedy[basemery[0]]\n",
    "    \n",
    "    # flatten and filter by score\n",
    "#     bresults = [mer for merlist in [basemerhashedb[x[0]] for x in b_scores[:5]] for mer in merlist]\n",
    "#     yresults = [mer for merlist in [basemerhashedy[x[0]] for x in y_scores[:5]] for mer in merlist]\n",
    "    \n",
    "    best_b_results = sorted(toscoreb, key=lambda mer: score_subsequence(s.spectrum, mer)[0], reverse=True)[:5]\n",
    "    best_y_results = sorted(toscorey, key=lambda mer: score_subsequence(s.spectrum, mer)[1], reverse=True)[:5]\n",
    "    resultfilteringtime += time.time() - rftst\n",
    "    #########################################################################\n",
    "    #                      /BIGGEST TIME TAKER BLOCK\n",
    "    #########################################################################\n",
    "    atst = time.time()\n",
    "    # try and create an alignment\n",
    "    spec_alignments = []\n",
    "    for bs in best_b_results:\n",
    "        bproteins = [id_ for id_, _ in db.tree.find_all(bs)]\n",
    "        for ys in best_y_results:\n",
    "            yproteins = [id_ for id_, _ in db.tree.find_all(ys)]\n",
    "            \n",
    "            # the sequence is from the same protein, try and overlap it\n",
    "            if any([x in yproteins for x in bproteins]):\n",
    "                spec_alignments.append(align_overlaps(bs, ys))\n",
    "            # otherwise just concatenate them \n",
    "            else: \n",
    "                spec_alignments.append(bs + '-' + ys)\n",
    "        \n",
    "    # remove repeats\n",
    "    a = list(set([x for x in spec_alignments if x is not None]))\n",
    "    # sort them by their score agains the spectrum and save them\n",
    "    alignments[i] = sorted(a, key=lambda x: score_subsequence(spectra[i]['spectrum'], x.replace('-', '')), reverse=True)[:5]\n",
    "    alignmenttime += time.time() - atst\n",
    "ttime = time.time() - st\n",
    "print(f'\\nDone. Time to complete: {round(ttime, 2)}s')\n",
    "print(f'Time breakdown: \\\n",
    "        \\nhash search time: {round(hashsearchtime, 2)}s,\\t {int(100 * hashsearchtime/ttime)}% \\\n",
    "        \\nresults filtering time: {round(resultfilteringtime, 2)}s, \\t {int(100 * resultfilteringtime / ttime)}% \\\n",
    "        \\nalignment time: {round(alignmenttime, 2)}s, \\t{int(100 * alignmenttime/ttime)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how well it did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-hybrid accuracy: 99/100 [99%]\n",
      "Hybrid accuracy: 152/245 [62]%\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "misses = 0\n",
    "hbhits = 0\n",
    "hbmisses = 0\n",
    "\n",
    "badones = []\n",
    "hybridmisses = []\n",
    "hybridhits = []\n",
    "for i in range(len(alignments)):\n",
    "#     if not len(alignments[i]):\n",
    "#         continue\n",
    "    # hits\n",
    "    if 'hybrid' not in peps[i]['peptide_name'].lower() and alignments[i][0] == peps[i]['sequence']:\n",
    "        hits += 1\n",
    "    elif 'hybrid' in peps[i]['peptide_name'].lower() and alignments[i][0] == peps[i]['hybrid_sequence']:\n",
    "        hbhits += 1\n",
    "        hybridhits.append((alignments[i][0], peps[i]['hybrid_sequence']))\n",
    "    \n",
    "    # misses\n",
    "    else: \n",
    "        if 'hybrid' in peps[i]['peptide_name'].lower():\n",
    "            hbmisses += 1\n",
    "            hybridmisses.append((peps[i]['hybrid_sequence'], alignments[i]))\n",
    "        else:\n",
    "            misses += 1\n",
    "            badones.append((alignments[i][0], peps[i]['sequence']))\n",
    "#     print('attempted alignment: {} \\t actual sequence: {}'.format(alignments[i][0], peps[i]['sequence']))\n",
    "\n",
    "print(f'Non-hybrid accuracy: {hits}/{hits + misses} [{int(100 * hits / (hits + misses))}%]')\n",
    "print(f'Hybrid accuracy: {hbhits}/{hbhits + hbmisses} [{int(100 * hbhits / (hbhits + hbmisses))}]%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('EVP-IKS', ['EVPLKS', 'EVPIKS', 'EVPL-PIKS', 'EVPI-PIKS', 'EVPI-PLKS'])\n",
      "('EVP-IKSL', ['EVP-LKSI', 'EVPIKSL', 'EVPL-IKSI', 'EVPI-IKSI', 'EVPI-LKSI'])\n",
      "('EVP-IKSLN', ['EVP-LKSIN', 'EVPL-KSIN', 'EVPI-KSIN', 'EVP-IKSLN', 'EVPI-LKSIN'])\n",
      "('EVP-IKSLNW', ['EVPL-KSLNW', 'EVP-IKSLNW', 'EVPI-KSLNW', 'EVPI-IKSLNW', 'EVPL-IKSLNW'])\n",
      "('EVP-IKSLNWY', ['EVPI-KSLNWY', 'EVPL-KSLNWY', 'EVP-IKSLNWY', 'EVPI-IKSLNWY', 'EVPL-IKSLNWY'])\n",
      "('EVP-IKSLNWYE', ['EVPI-KSLNWYE', 'EVPL-KSLNWYE', 'EVPI-IKSLNWYE', 'EVPL-IKSLNWYE', 'EVPIRLDYHGKHVSMD-IKSLNWYE'])\n",
      "('EVP-IKSLNWYED', ['EVPI-KSLNWYED', 'EVPL-KSLNWYED', 'EVPL-IKSLNWYED', 'EVPI-IKSLNWYED', 'EVIPNDEEQI-IKSLNWYED'])\n",
      "('QEVP-IKS', ['QEV-PIKS', 'QEVP-IQDPLKS', 'QEVP-PIKS', 'QEVP-PLKS', 'QEV-IQDPLKS'])\n",
      "('QEVP-IKSL', ['QEVP-IKSI', 'QEV-PIKSL', 'QEVP-LKSI', 'QEVP-PIKSL', 'QEVREPAP-LKSI'])\n",
      "('QEVP-IKSLN', ['QEVP-LKSIN', 'QEVP-IKSLN', 'QEVREPAP-LKSIN', 'QEVREPAP-IKSLN', 'QEVREPAP-KSIN'])\n",
      "('AQEVP-IKS', ['AQEV-PIKS', 'AQEV-PLKS', 'AAGEV-PIKS', 'AAGEV-PLKS', 'AQEVP-IQDPLKS'])\n",
      "('AQEVP-IKSL', ['AQEV-PIKSL', 'AQEVP-IKSL', 'AQEVP-LKSL', 'AAGEV-PIKSL', 'AQEVP-PIKSL'])\n",
      "('AQEVP-IKSLN', ['AQEVP-LKSIN', 'AQEVP-IKSLN', 'AQEVP-KSLN', 'AAGEV-IKSLN', 'AAGEV-LKSIN'])\n",
      "('PAQEVP-IKS', ['PAQEV-PIKS', 'PAQEV-PLKS', 'PAQEVP-IQDPLKS', 'PAQEVP-PLKS', 'PAQEVP-PIKS'])\n",
      "('PAQEVP-IKSL', ['PAQEVP-LKSL', 'PAQEVP-IKSL', 'PAQEV-PIKSL', 'PAQEVP-PIKSL', 'PAQEV-LKSL'])\n",
      "('VPAQEVP-IKS', ['VPAQEV-PLKS', 'VPAQEV-PIKS', 'VPAQEVP-IQDPLKS', 'VPAQEVP-PLKS', 'VPAQEVP-PIKS'])\n",
      "('VPAQEVP-IKSL', ['VPAQEVP-IKSI', 'VPAQEVP-LKSI', 'VPAQEV-PIKSL', 'VPAQEVP-PIKSL', 'VPAQEV-LKSI'])\n",
      "('VPAQEVP-IKSLN', ['VPAQEVP-LKSIN', 'VPAQEVP-IKSLN', 'VPAQEVP-KSLN', 'VPAQEV-IKSLN', 'VPAQEV-LKSIN'])\n",
      "('IVPAQEVP-IKS', ['IVPAQEV-PIKS', 'IVPAQEV-PLKS', 'IVPAQEVP-IQDPLKS', 'IVPAQEVP-PLKS', 'IVPAQEVP-PIKS'])\n",
      "('IVPAQEVP-IKSL', ['IVPAQEV-PIKSL', 'IVPAQEVP-LKSL', 'IVPAQEVP-IKSL', 'IVPAQEVP-PIKSL', 'IVPAQEV-IKSL'])\n",
      "('IVPAQEVP-IKSLN', ['IVPAQEVP-LKSIN', 'IVPAQEVP-IKSLN', 'IVPAQEVP-KSLN', 'IVPAQEV-LKSIN', 'IVPAQEV-IKSLN'])\n",
      "('AIVPAQEVP-IKS', ['AIVPAQEV-PIKS', 'AIVPAQEV-PLKS', 'AIVPAQEVP-PSAPHKIQDPLKS', 'AIVPAQEV-PSAPHKIQDPLKS', 'AIVPAQEVP-PIKS'])\n",
      "('AIVPAQEVP-IKSL', ['AIVPAQEVP-LKSI', 'AIVPAQEVP-IKSI', 'AIVPAQEV-PIKSL', 'AIVPAQEVP-PIKSL', 'AIVPAQEV-IKSI'])\n",
      "('IVQ-PAR', ['LVQPAR', 'IVQP-AGPAR', 'LVQP-AGPAR', 'LVQAPR-QPAR', 'LVQAPR-AGPAR'])\n",
      "('IVQ-PARD', ['IVQP-ARD', 'LVQAPR-IKLANITAMDKARD', 'LVQAPRRD', 'IVQP-PARD', 'LVQP-PARD'])\n",
      "('IVQ-PARDV', ['IVQP-ARDV', 'LVQP-ARDV', 'LVQAPRDV', 'LVQAPR-PARDV', 'LVQAPR-ARDV'])\n",
      "('IVQ-PARDVV', ['LVQP-ARDVV', 'IVQP-ARDVV', 'IVQF-ARDVV', 'IVQF-PARDVV', 'LVQP-PARDVV'])\n",
      "('IVQ-PARDVVD', ['IVQP-ARDVVD', 'LVQP-ARDVVD', 'LVQAPR-PARDVVD', 'LVQAPR-ARDVVD', 'LVQAPR-RDVVD'])\n",
      "('IVQ-PARDVVDA', ['LVQP-ARDVVDA', 'IVQP-ARDVVDA', 'LVQCGKGQGVVI-PARDVVDA', 'LVQCGKGQGVVI-ARDVVDA', 'LVQCGKGQGVVI-RDVVDA'])\n",
      "('IVQ-PARDVVDAF', ['LVQP-ARDVVDAF', 'IVQP-ARDVVDAF', 'IVQP-RDVVDAF', 'LVQP-RDVVDAF', 'LVQAPR-PARDVVDAF'])\n",
      "('SIVQ-PARDVVD', ['SLVQ-PARDVVD', 'SIVQ-PARDVVD', 'SLVQVQP-ARDVVD', 'SLVQVQP-PARDVVD', 'SLVQVQP-RDVVD'])\n",
      "('SIVQ-PARDVVDAF', ['SLVQ-PARDVVDAF', 'SIVQ-PARDVVDAF', 'SLVQVQP-ARDVVDAF', 'SLVQVQP-PARDVVDAF', 'SLVQVQP-RDVVDAF'])\n",
      "('RDSIVQ-PAR', ['RDSIV-QPAR', 'RDSIVQ-EPAR', 'RDSIVQ-EARPAR', 'RDSIVQ-QPAR', 'RDSIV-EPAR'])\n",
      "('LRDSIVQ-PAR', ['LRDSIV-QPAR', 'LRDSIVQCELLMLRV-QPAR', 'LRDSIVQCELLMLRV-EPAR', 'LRDSIVQCELLMLRV-SLPNLAR', 'LRDSIVQ-EPAR'])\n",
      "('ELRDSIVQ-PAR', ['ELRDSIV-QPAR', 'ELRDSIVQ-PFALGGPAR', 'ELRDSIVQ-QPAR', 'ELRDSIVQ-SLPNLAR', 'ELRDSIV-PFALGGPAR'])\n",
      "('WELRDSIVQ-PAR', ['WELRDSIV-QPAR', 'WELRDSIVQ-PAR', 'WELRDSIVQ-PFALGGPAR', 'WELRDSIVQ-QPAR', 'WELRDSIV-PFALGGPAR'])\n",
      "('NPS-DFD', ['NPSD-DFD', 'GGPS-DSFD', 'NPSD-SDFD', 'NPSD-DSFD', 'GGPS-SDFD'])\n",
      "('NPS-DFDS', ['NPSD-FDS', 'NPS-DFDS', 'GGPS-DFDS', 'NPSD-DFDS', 'GGPS-DENPSDSSSDS'])\n",
      "('NPS-DFDSF', ['NPSD-FDSF', 'NPS-DFDSF', 'GGPS-DFDSF', 'NPSD-DFDSF', 'NPSD-DSF'])\n",
      "('NPS-DFDSFL', ['NPSD-FDSFL', 'NPS-DFDSFL', 'NPSD-DFDSFL', 'NPSD-DSFL', 'GGPSELFPDNKNND-FDSFL'])\n",
      "('NPS-DFDSFLA', ['NPSD-FDSFLA', 'NPS-DFDSFLA', 'NPSD-DFDSFLA', 'GGPSFQPEFF-DSFLA', 'NPSD-DSFLA'])\n",
      "('NPS-DFDSFLAL', ['NPSD-FDSFLAL', 'NPSDVKEHHY-DSFLAL', 'NPSD-DFDSFLAL', 'NPSDVKEHHY-DFDSFLAL', 'NPSDVKEHHY-FDSFLAL'])\n",
      "('NPS-DFDSFLALP', ['NPSD-FDSFLALP', 'NPSD-DFDSFLALP', 'NPSDVKEHHY-DFDSFLALP', 'NPSDVKEHHY-FDSFLALP', 'NPSD-DSFLALP'])\n",
      "('YSGNPS-DFD', ['YSGNP-SDFD', 'YSGNPS-DFD', 'YSGNPS-SDFD', 'YSGNPS-WTAPGEDFD', 'YSGNP-DFD'])\n",
      "('LYSGNPS-DFD', ['LYSGNP-SDFD', 'LYSGNPS-DFD', 'LYSGNPS-DWMLEKMDLKEFDFD', 'LYSGNPS-SDFD', 'LYSGNP-DFD'])\n",
      "('ELYSGNPS-DFD', ['ELYSGNP-SDFD', 'ELYSGNPS-DFD', 'ELYSGNPS-SDFD', 'ELYSGNPS-EQFPEGFQFD', 'ELYSGNP-EQFPEGFQFD'])\n",
      "('RELYSGNPS-DFD', ['RELYSGNP-SDFD', 'RELYSGNPS-DFD', 'RELYSGNPS-SDFD', 'RELYSGNPS-TFVNGHSKDFD', 'RELYSGNP-TFVNGHSKDFD'])\n",
      "('LLP-GLS', ['LLPGLS', 'LLPGLS-LPGIS', 'LLPGI-LPGIS', 'LLPGL-LPGIS', 'LLPGI-LPGLS'])\n",
      "('LLP-GLSQ', ['LLPGLS-LPGISQ', 'LLPGLS-PGISQ', 'LLPGLS-GLSQ', 'LLPGI-LPGISQ', 'LLPGL-LPGISQ'])\n",
      "('LLP-GLSQD', ['LLPGLS-GLSQD', 'LLPGLS-LSQD', 'LLPGLS-ISQD', 'LLPGL-ISQD', 'LLPGI-LSQD'])\n",
      "('LLP-GLSQDT', ['LLPGI-SQDT', 'LLPGL-SQDT', 'LLPGLS-GLSQDT', 'LLPGLS-LSQDT', 'LLPGLS-SQDT'])\n",
      "('LLP-GLSQDTF', ['LLPGL-SQDTF', 'LLPGI-SQDTF', 'LLPGLS-GLSQDTF', 'LLPGLS-LSQDTF', 'LLPGLS-SQDTF'])\n",
      "('LLP-GLSQDTFK', ['LLPGI-SQDTFK', 'LLPGL-SQDTFK', 'LLPGLS-GLSQDTFK', 'LLPGLS-LSQDTFK', 'LLPGLS-SQDTFK'])\n",
      "('LLP-GLSQDTFKI', ['LLPGL-SQDTFKI', 'LLPGI-SQDTFKI', 'LLPGLS-GLSQDTFKI', 'LLPGLS-LSQDTFKI', 'LLPGLS-SQDTFKI'])\n",
      "('PLLP-GLS', ['PLLPGLS', 'PLLPGLLPGLS', 'PLLPGLPGLS'])\n",
      "('PLLP-GLSQ', ['PLLPGLS-LPGISQ', 'PLLPGLS-PGISQ', 'PLLPGLS-GLSQ', 'PLLPGL-LPGISQ', 'PLLPG-LPGISQ'])\n",
      "('PLLP-GLSQD', ['PLLPG-ISQD', 'PLLPG-LSQD', 'PLLPGLS-GLSQD', 'PLLPGLS-LSQD', 'PLLPGLS-ISQD'])\n",
      "('PLLP-GLSQDT', ['PLLPGL-SQDT', 'PLLPG-LSQDT', 'PLLPGLS-GLSQDT', 'PLLPGLS-LSQDT', 'PLLPGLS-SQDT'])\n",
      "('PLLP-GLSQDTF', ['PLLPGL-SQDTF', 'PLLPG-LSQDTF', 'PLLPGLS-GLSQDTF', 'PLLPGLS-LSQDTF', 'PLLPGLS-SQDTF'])\n",
      "('PLLP-GLSQDTFK', ['PLLPG-LSQDTFK', 'PLLPGL-SQDTFK', 'PLLPGLS-GLSQDTFK', 'PLLPGLS-LSQDTFK', 'PLLPGLS-SQDTFK'])\n",
      "('PLLP-GLSQDTFKI', ['PLLPGL-SQDTFKI', 'PLLPG-LSQDTFKI', 'PLLPGLS-SQDTFKI', 'PLLPGLS-GLSQDTFKI', 'PLLPGLS-LSQDTFKI'])\n",
      "('APLLP-GLS', ['APLLP-LLPGLS', 'APLLP-PLLPGLS', 'APIL-PLLPGLS', 'APII-PLLPGLS', 'APLLP-LPGLS'])\n",
      "('APLLP-GLSQ', ['APIL-PGISQ', 'APII-PGISQ', 'APLLP-GLSQ', 'APLLP-LPGISQ', 'APLLP-PGISQ'])\n",
      "('LAPLLP-GLS', ['LAPLL-PLLPGLS', 'LAPLLP-LLPGLS', 'IAPIL-PLLPGLS', 'LAPLLP-PLLPGLS', 'LAPLLP-LPGLS'])\n",
      "('LAPLLP-GLSQ', ['IAPIL-PGISQ', 'LAPLLP-GLSQ', 'LAPLL-PGISQ', 'LAPLLP-LPGISQ', 'LAPLLP-PGISQ'])\n",
      "('DLAPLLP-GLS', ['DLAPLLP-PLLPGLS', 'DLAPII-PLLPGLS', 'DLAPLLP-LLPGLS', 'DLAPLL-PLLPGLS', 'DLAPLLP-LPGLS'])\n",
      "('DLAPLLP-GLSQ', ['DLAPLL-PGISQ', 'DLAPII-PGISQ', 'DLAPLLP-GISQ', 'DLAPLLP-LPGISQ', 'DLAPLLP-PGISQ'])\n",
      "('MDLAPLLP-GLS', ['MDLAPL-LPGIS', 'MDLAPLL-PLLPGLS', 'MDLAPLLP-LLPGLS', 'MDLAPLLP-PLLPGLS', 'MDLAPLLP-LPGIS'])\n",
      "('MDLAPLLP-GLSQ', ['MDLAPLL-PGISQ', 'MDLAPL-LPGISQ', 'MDLAPLLP-GLSQ', 'MDLAPLLP-LPGISQ', 'MDLAPLLP-PGISQ'])\n",
      "('TMDLAPLLP-GLS', ['TMDLAPL-LPGLS', 'TMDLAPLLP-PLLPGLS', 'TMDLAPLLP-LLPGLS', 'TMDLAPLL-PLLPGLS', 'TMDLAPLLP-LPGLS'])\n",
      "('TMDLAPLLP-GLSQ', ['TMDLAPL-LPGISQ', 'TMDLAPLL-PGISQ', 'TMDLAPLLP-GISQ', 'TMDLAPLLP-LPGISQ', 'TMDLAPLLP-PGISQ'])\n",
      "('SAI-LVG', ['SALL-VPLVG', 'SAIL-VPLVG', 'SALI-VPLVG', 'SAIL-IPVG', 'SALL-IPVG'])\n",
      "('SAI-LVGF', ['SALLVGF', 'SAILVGF', 'SAIL-IVGF', 'SALI-IVGF', 'SAIL-LIVGF'])\n",
      "('SAI-LVGFV', ['SALI-VGFV', 'SAILVGFV', 'SALL-VGFV', 'SALI-LVGFV', 'SALL-LVGFV'])\n",
      "('SAI-LVGFVL', ['SALI-VGFVI', 'SALL-VGFVI', 'SAILVGFVL', 'SALI-VGFVL', 'SALL-VGFVL'])\n",
      "('SAI-LVGFVLY', ['SALL-VGFVLY', 'SALI-VGFVLY', 'SALIF-VGFVLY', 'SALLF-VGFVLY', 'SALI-GFVLY'])\n",
      "('SAI-LVGFVLYT', ['SALL-VGFVLYT', 'SALI-VGFVLYT', 'SALLF-VGFVLYT', 'SALIF-VGFVLYT', 'SALI-LVGFVLYT'])\n",
      "('SAI-LVGFVLYTF', ['SALI-VGFVLYTF', 'SALL-VGFVLYTF', 'SALLF-VGFVLYTF', 'SALIF-VGFVLYTF', 'SALL-LVGFVLYTF'])\n",
      "('DSAI-LVG', ['DSALLR-LLVG', 'DSALLR-ILVG', 'DSALLR-IIVG', 'DSAIL-ILVG', 'DSALL-LLVG'])\n",
      "('DSAI-LVGF', ['DSALLR-LIVGF', 'DSALLR-LVGF', 'DSALLR-IVGF', 'DSAIL-LVGF', 'DSAIL-IVGF'])\n",
      "('DSAI-LVGFV', ['DSAIL-VGFV', 'DSALL-VGFV', 'DSALLR-LVGFV', 'DSALLR-LVLGFV', 'DSALLR-VGFV'])\n",
      "('DSAI-LVGFVL', ['DSAIL-VGFVI', 'DSAIL-VGFVL', 'DSALL-VGFVL', 'DSALL-VGFVI', 'DSALLR-LVGFVL'])\n",
      "('DSAI-LVGFVLY', ['DSAIL-VGFVLY', 'DSALL-VGFVLY', 'DSALLR-LVGFVLY', 'DSALLR-VGFVLY', 'DSALLR-GFVLY'])\n",
      "('DSAI-LVGFVLYT', ['DSAIL-VGFVLYT', 'DSALL-VGFVLYT', 'DSALLR-LVGFVLYT', 'DSALLR-VGFVLYT', 'DSALLR-GFVLYT'])\n",
      "('DSAI-LVGFVLYTF', ['DSALL-VGFVLYTF', 'DSAIL-VGFVLYTF', 'DSALLR-VGFVLYTF', 'DSALLR-LVGFVLYTF', 'DSALLR-GFVLYTF'])\n",
      "('GDSAI-LVG', ['GDSA-IIVG', 'GDSA-ILVG', 'GDSA-LIVG', 'GDSAI-IIVG', 'GDSAI-LIVG'])\n",
      "('DGDSAI-LVG', ['DGDSA-ILVG', 'DGDSA-LLVG', 'DGDSA-IIVG', 'DGDSAI-LLVG', 'DGDSAI-IIVG'])\n",
      "('DGDSAI-LVGF', ['DGDSA-LIVGF', 'DGDSAI-IVGF', 'DGDSAI-LVGF', 'DGDGTI-IVGF', 'DGDGTI-LVGF'])\n",
      "('QDGDSAI-LVG', ['QDGDSA-LLVG', 'QDGDSA-ILVG', 'QDGDSA-IIVG', 'QDGDSAI-IIVG', 'QDGDSAI-ILVG'])\n",
      "('QDGDSAI-LVGF', ['QDGDSAI-IVGF', 'QDGDSA-LIVGF', 'QDGDSAI-LVGF', 'QDGDSAI-LIVGF', 'QDGDSA-IVGF'])\n",
      "('DQDGDSAI-LVG', ['DQDGDSA-ILVG', 'DQDGDSA-IIVG', 'DQDGDSA-LLVG', 'DQDGDSAI-ILVG', 'DQDGDSAI-IIVG'])\n",
      "('DQDGDSAI-LVGF', ['DQDGDSA-LIVGF', 'DQDGDSAI-IVGF', 'DQDGDSAI-LVGF', 'DQDGDSAI-LIVGF', 'DQDGDSA-IVGF'])\n",
      "('ADQDGDSAI-LVG', ['ADQDGDSA-LLVG', 'ADQDGDSA-ILVG', 'ADQDGDSA-IIVG', 'ADQDGDSAI-ILVG', 'ADQDGDSAI-LLVG'])\n"
     ]
    }
   ],
   "source": [
    "for hm in hybridmisses:\n",
    "    print(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spectrum': [132.04776143499998,\n",
       "  203.084875435,\n",
       "  316.16893943499997,\n",
       "  502.248252435,\n",
       "  573.285366435],\n",
       " 'precursor_mass': 591.2959311000001}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_spectrum('MALWA', ion='b', charge=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
