{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue with missing ion peaks\n",
    "For spectra with missing ions, we still want to be able to sequence them. With non-hybrid sequences, this really isn't that much of a problem, as hopefully the b ions make up for some of the missing y ions and vice versa. However, especially in the case of unbalanced ions. The picture kind of shows the issue\n",
    "\n",
    "![](../unbalancedIons.png)\n",
    "\n",
    "In this case, there are enough b-ions to describe the left k-mer but not enough y-ions to describe the right k-mer. What we need to do is try new extensions after getting top scoring k-mers to try and describe the b-ions found all the way on the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing steps\n",
    "So we want to load some proteins, create both non-hybrid and hybrid peptides, make it lopsided like the picture, then run hypedsearch and see how well it does\n",
    "1. Load fasta file\n",
    "2. Make peptides\n",
    "    1. Make non-hybrid peptides\n",
    "    2. Make hybrid peptides\n",
    "3. Remove b or y ion peaks to make spectrum unbalanced\n",
    "4. Run hypedsearch\n",
    "5. Load results and see what alignmets were made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from modules.sequence_generation import write_spectra\n",
    "from collections import namedtuple\n",
    "from src.spectra import gen_spectra\n",
    "from pyteomics.mzxml import read as mzxmlread\n",
    "from src.file_io import fasta\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = '../../testing framework/data/databases/4prots.fasta'\n",
    "db = {x['name']: x for x in fasta.read(fasta_file)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make peptides \n",
    "We will make 4 peptides with 6 spectra:\n",
    "* Non hybrid peptide with all ions\n",
    "* 2 cases of another non hybrid peptide:\n",
    "    * Missing lots of b ions\n",
    "    * Missing lots of y ions\n",
    "* Hybrid peptide with all ions\n",
    "* 2 cases of another hybrid peptide:\n",
    "    * Missing lots of b ions\n",
    "    * Missing lots of y ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theres only 4 proteins, so use the first 2 to make the first 3 spectra, and the second 2 for the other 3\n",
    "peptide = namedtuple('peptide', ['hybrid', 'left', 'right', 'sequence', 'hybrid_sequence'])\n",
    "min_len = 7\n",
    "max_len = 15\n",
    "hp_min_len = 4\n",
    "hp_max_len = 8\n",
    "protkeys = list(db.keys())\n",
    "\n",
    "get_start = lambda protlen: random.randint(0, protlen - max_len)\n",
    "p1s = get_start(len(db[protkeys[0]]['sequence']))\n",
    "p2s = get_start(len(db[protkeys[1]]['sequence']))\n",
    "p1 = peptide(False, protkeys[0], protkeys[0], db[protkeys[0]]['sequence'][p1s: p1s + random.randint(min_len, max_len)], '')\n",
    "p2 = peptide(False, protkeys[1], protkeys[1], db[protkeys[1]]['sequence'][p2s: p2s + random.randint(min_len, max_len)], '')\n",
    "\n",
    "hp1ls = get_start(len(db[protkeys[2]]['sequence']))\n",
    "hp1rs = get_start(len(db[protkeys[3]]['sequence']))\n",
    "hp1seq = db[protkeys[2]]['sequence'][hp1ls: hp1ls + random.randint(hp_min_len, hp_max_len)] + '-' + db[protkeys[3]]['sequence'][hp1rs: hp1rs + random.randint(hp_min_len, hp_max_len)]\n",
    "hp1 = peptide(True, protkeys[2], protkeys[3], hp1seq.replace('-', ''), hp1seq)\n",
    "\n",
    "hp2ls = get_start(len(db[protkeys[2]]['sequence']))\n",
    "hp2rs = get_start(len(db[protkeys[3]]['sequence']))\n",
    "hp2seq = db[protkeys[2]]['sequence'][hp2ls: hp2ls + random.randint(hp_min_len, hp_max_len)] + '-' + db[protkeys[3]]['sequence'][hp2rs: hp2rs + random.randint(hp_min_len, hp_max_len)]\n",
    "hp2 = peptide(True, protkeys[2], protkeys[3], hp2seq.replace('-', ''), hp2seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make unbalanced spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_small_count = 4\n",
    "spec1 = gen_spectra.gen_spectrum(p1.sequence[:-1])['spectrum']\n",
    "spec2b = gen_spectra.gen_spectrum(p2.sequence[:-1], ion='b')['spectrum'] + gen_spectra.gen_spectrum(p2.sequence[len(p2.sequence) - random.randint(1, max_small_count+1):], ion='y')['spectrum']\n",
    "spec2y = gen_spectra.gen_spectrum(p2.sequence[:random.randint(0, max_small_count)], ion='b')['spectrum'] + gen_spectra.gen_spectrum(p2.sequence[:-1], ion='y')['spectrum']\n",
    "spec3 = gen_spectra.gen_spectrum(hp1.sequence[:-1])['spectrum']\n",
    "spec4b = gen_spectra.gen_spectrum(hp2.sequence[:-1], ion='b')['spectrum'] + gen_spectra.gen_spectrum(hp2.sequence[len(hp2.sequence) - random.randint(1, max_small_count+1):], ion='y')['spectrum']\n",
    "spec4y = gen_spectra.gen_spectrum(hp2.sequence[:random.randint(0, max_small_count)], ion='b')['spectrum'] + gen_spectra.gen_spectrum(hp2.sequence[:-1], ion='y')['spectrum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = [\n",
    "    {'spectrum': spec1, 'precursor_mass': gen_spectra.gen_spectrum(p1.sequence[:-1])['precursor_mass']},\n",
    "    {'spectrum': spec2b, 'precursor_mass': gen_spectra.gen_spectrum(p2.sequence[:-1])['precursor_mass']},\n",
    "    {'spectrum': spec2y, 'precursor_mass': gen_spectra.gen_spectrum(p2.sequence[:-1])['precursor_mass']},\n",
    "    {'spectrum': spec3, 'precursor_mass': gen_spectra.gen_spectrum(hp1.sequence[:-1])['precursor_mass']}, \n",
    "    {'spectrum': spec4b, 'precursor_mass': gen_spectra.gen_spectrum(hp2.sequence[:-1])['precursor_mass']},\n",
    "    {'spectrum': spec4y, 'precursor_mass': gen_spectra.gen_spectrum(hp2.sequence[:-1])['precursor_mass']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../testing framework/data/testing_output/unbalancedSpectra.mzML'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_spectra.write_mzml('unbalancedSpectra', spectra, output_dir='../../testing framework/data/testing_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run hypedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database...\n",
      "Done. Indexing database...\n",
      "1426 unique kmers\n",
      "Done.\n",
      "Number of 3-mers found in the database: 1426\n",
      "Analyzing spectra file 0/1[0%]\n",
      "\n",
      "Finished search. Writting results to .../data/testing_output/...\n"
     ]
    }
   ],
   "source": [
    "from src import runner\n",
    "\n",
    "test_directory = '../data/testing_output/'\n",
    "spec_dir = '../data/spectra/'\n",
    "\n",
    "args = {\n",
    "    'spectra_folder': spec_dir,\n",
    "    'database_file': fasta_file,\n",
    "    'output_dir': test_directory,\n",
    "    'min_peptide_len': 3,\n",
    "    'max_peptide_len': 35,\n",
    "}\n",
    "runner.run(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/testing_output/summary.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ba60e369d917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msummary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/testing_output/summary.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_scanno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msumm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/testing_output/summary.json'"
     ]
    }
   ],
   "source": [
    "summary_file = '../data/testing_output/summary.json'\n",
    "\n",
    "summ = json.load(open(summary_file, 'r'))\n",
    "\n",
    "for file_scanno, result in summ.items():\n",
    "    print(result['alignments'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
