{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test new kmer extension\n",
    "While the last one was sort of fast, lets make it faster if we can\n",
    "Instead of looking at all points of interest and try and just brute force it with a tree beam search kind of thing\n",
    "\n",
    "### lets first see how big these things get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=3, size=0.295016MB, len=8477\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.types.database import Database\n",
    "fasta_file = '../../testing framework/data/databases/6000prots.fasta'\n",
    "db = Database(fasta_file, True, 1)\n",
    "kmers = [i for i in range(3, 4)]\n",
    "for kmer in kmers:\n",
    "    db.kmer_size = kmer\n",
    "    db.index()\n",
    "    dictsize = sys.getsizeof(db.metadata) / 1000000\n",
    "    numkmers = len(db.metadata)\n",
    "    print('for k={}, size={}MB, len={}'.format(kmer, dictsize, numkmers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the optimized initial kmer search to look for best looking spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for both\n",
    "#### 1. Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastafile = '../../testing framework/data/databases/100prots.fasta'\n",
    "db = Database(fastafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.types.objects import Spectrum\n",
    "from src.file_io import fasta\n",
    "from modules.sequence_generation import peptides\n",
    "from src.spectra.gen_spectra import gen_spectrum\n",
    "import math\n",
    "\n",
    "database = fasta.read(fastafile, True)\n",
    "\n",
    "database = {x['name']: x for x in database}\n",
    "\n",
    "num_hybs = 5\n",
    "min_length= 5\n",
    "max_length = 35\n",
    "num_peptides = 1000\n",
    "min_cont = 3 #min contribution for each side of a hybrid\n",
    "\n",
    "# create peptides\n",
    "non_hybrid_peps = peptides.gen_peptides([x for _, x in database.items()], num_peptides, min_length=min_length, max_length=max_length, digest='random', dist='beta')\n",
    "# create hybrid peptides\n",
    "\n",
    "all_proteins_raw = [x for _,x in database.items()]\n",
    "all_peptides_raw = non_hybrid_peps \n",
    "\n",
    "peps = {}\n",
    "for i, pep in enumerate(all_peptides_raw):\n",
    "    peps[i] = pep\n",
    "    peps[i]['scan_no'] = i\n",
    "\n",
    "spectra = []\n",
    "sorted_keys = [int(c) for c in peps.keys()]\n",
    "sorted_keys.sort()\n",
    "for k in sorted_keys:\n",
    "    pep = peps[k]\n",
    "    cont = gen_spectrum(pep['sequence'])\n",
    "    spec = cont['spectrum']\n",
    "    pm = cont['precursor_mass']\n",
    "    spectra.append({'spectrum': spec, 'precursor_mass': pm})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "MassSequence = namedtuple('MassSequence', ['mass', 'sequence'])\n",
    "\n",
    "def make_all_base_mers_hash(database: Database, base_mer: int) -> defaultdict:\n",
    "    '''\n",
    "    Create the list of all the base mers from 1 to base_mer with mass, protein, start position information\n",
    "    \n",
    "    Inputs:\n",
    "        database:    (Database) source of the sequences\n",
    "        base_mer:    (int) the base k-mer to make up to\n",
    "    Outputs:\n",
    "        list of MassSequence for all singly, doubly b and y masses\n",
    "    '''\n",
    "    allbasemers = defaultdict(list)\n",
    "    database.set_kmer_size(base_mer)\n",
    "    database.index()\n",
    "    md = database.metadata\n",
    "    for mer in md:\n",
    "        mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        rev_mer = mer[::-1]\n",
    "        rev_mer_spec = gen_spectrum(mer)['spectrum']\n",
    "        for mass in mer_spec:\n",
    "            mass_key = math.floor(mass)\n",
    "            allbasemers[mass_key].append(MassSequence(mass, mer))\n",
    "\n",
    "    return allbasemers\n",
    "\n",
    "def seach_base_kmers_hash(observed: Spectrum, allbasemers: dict, tolerance: float) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        allbasemers: (dict of list of MassSequence) all of the basemers made from the function 'make_all_base_mers_hash'\n",
    "        tolerance:   (float) the ppm tolerance to accept for each mass\n",
    "    Outputs:\n",
    "        list of MassSequence for all masses that were in the acceptable range of an observed mass\n",
    "    '''\n",
    "    hits = []\n",
    "    for mass in observed.spectrum:\n",
    "        tol = ppm_opt(mass, tolerance)\n",
    "        lb_mass = mass - tol\n",
    "        ub_mass = mass + tol\n",
    "        lb_mass_key = math.floor(lb_mass)\n",
    "        ub_mass_key = math.floor(ub_mass)\n",
    "        \n",
    "        hits += [x.sequence for x in allbasemers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "        if lb_mass_key != ub_mass_key:\n",
    "            hits += [x.sequence for x in allbasemers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "            \n",
    "    return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_peptide_len = 20\n",
    "max_pep_len = 20\n",
    "\n",
    "st = time.time()\n",
    "db = Database(fasta_file, True)\n",
    "allmers = make_all_base_mers_hash(db, max_pep_len)\n",
    "speclen = len(spectra)\n",
    "hs_res_dict = {}\n",
    "mer_counter = Counter()\n",
    "tracker = []\n",
    "\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('spectrum {}/{}\\r'.format(i, speclen), end='')\n",
    "    s = Spectrum(spec['spectrum'], [], '2', 0, spec['precursor_mass'], '')\n",
    "    res = seach_base_kmers_hash(s, allmers, 20)\n",
    "    mer_counter(res)\n",
    "    tracker = [c for _, c in mer_counter.most_common()]\n",
    "    \n",
    "print('\\ntotal time for pure hash method: {}'.format(time.time() - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
