{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New k-mer extension that happens more globally\n",
    "Make it run faster.\n",
    "\n",
    "Steps:\n",
    "1. Index the database \n",
    "2. Build a hash table of the masses of all b+, b++, y+, and y++ ions and masses\n",
    "3. Search for all sequences that get mass hits\n",
    "4. Filter the results\n",
    "5. Attempt aligments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: latin-1 -*-\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.types.database import Database\n",
    "from src.types.objects import Spectrum\n",
    "from src.file_io import fasta\n",
    "from modules.sequence_generation import proteins, peptides\n",
    "from src.spectra.gen_spectra import gen_spectrum\n",
    "from src.scoring.scoring import score_subsequence\n",
    "\n",
    "import math\n",
    "from collections import namedtuple, defaultdict, deque\n",
    "import time\n",
    "import bisect\n",
    "from operator import itemgetter\n",
    "from typing import Iterable, Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_by_key(value: Any, a: Iterable, key: str) -> int:\n",
    "    '''\n",
    "    index of insertion\n",
    "    '''\n",
    "    if len(a) == 0:\n",
    "        return 0\n",
    "    elif len(a) == 1:\n",
    "        return 1 if getattr(a[0], key) <= getattr(value, key) else 0\n",
    "    \n",
    "    mid = floor(len(a)/2)\n",
    "    if getattr(a[mid-1], key) <= getattr(value, key) <= getattr(a[mid], key):\n",
    "        return mid\n",
    "    elif getattr(a[mid], key) > getattr(value, key):\n",
    "        return mid - insort_by_key(value, a[:mid], key)\n",
    "    else:\n",
    "        return mid + insort_by_key(value, a[mid:], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insort_by_key(value: Any, a: Iterable, key: str) -> Iterable:\n",
    "    '''\n",
    "    '''\n",
    "    if len(a) == 0:\n",
    "        return [value]\n",
    "    elif len(a) == 1:\n",
    "        return a + [value] if getattr(a[0], key) <= getattr(value, key) else [value] + a\n",
    "    \n",
    "    mid = math.floor(len(a)/2)\n",
    "    if getattr(a[mid-1], key) <= getattr(value, key) <= getattr(a[mid], key):\n",
    "        return a[:mid] + [value] + a[mid:]\n",
    "    elif getattr(a[mid], key) > getattr(value, key):\n",
    "        return insort_by_key(value, a[:mid], key) + a[mid:]\n",
    "    else:\n",
    "        return a[:mid] + insort_by_key(value, a[mid:], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insort_by_index(value: Any, a: Iterable, index: int) -> Iterable:\n",
    "    '''\n",
    "    '''\n",
    "    if len(a) == 0:\n",
    "        return [value]\n",
    "    elif len(a) == 1:\n",
    "        return a + [value] if a[0][index] <= value[index] else [value] + a\n",
    "    \n",
    "    mid = math.floor(len(a)/2)\n",
    "    if a[mid-1][index] <= value[index] <= a[mid][index]:\n",
    "        return a[:mid] + [value] + a[mid:]\n",
    "    elif a[mid][index] > value[index]:\n",
    "        return insort_by_index(value, a[:mid], index) + a[mid:]\n",
    "    else:\n",
    "        return a[:mid] + insort_by_index(value, a[mid:], index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_exact_by_key(value: Any, a: Iterable, key: str) -> int:\n",
    "    '''\n",
    "    '''\n",
    "    if len(a) == 0:\n",
    "        return -1\n",
    "    i = bisect.bisect_left([getattr(x, key) for x in a], value)\n",
    "    if i < len(a) and getattr(a[i], key) == value:\n",
    "        return i\n",
    "    elif i+1 < len(a) and getattr(a[i+1], key) == value:\n",
    "        return i+1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global extension and addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MassSequence = namedtuple('MassSequence', ['mass', 'sequence'])\n",
    "\n",
    "def ppm_to_da(reference: float, ppm_tolerance: float) -> float:\n",
    "    '''\n",
    "    Calculate the ppm difference between the observed and actual\n",
    "    '''\n",
    "    return abs((ppm_tolerance / 1000000)*reference)\n",
    "\n",
    "\n",
    "def search_kmers_hash(observed: Spectrum, kmers: dict, tolerance: float) -> list:\n",
    "    '''\n",
    "    Search through all of the base kmers and find those that gave us good hits\n",
    "    \n",
    "    Inputs:\n",
    "        spectrum:    (Spectrum) what to sequence\n",
    "        allbasemers: (dict of list of MassSequence) all of the basemers made from the function 'make_all_base_mers_hash'\n",
    "        tolerance:   (float) the ppm tolerance to accept for each mass\n",
    "    Outputs:\n",
    "        list of MassSequence for all masses that were in the acceptable range of an observed mass\n",
    "    '''\n",
    "    hits = []\n",
    "    for mass in observed.spectrum:\n",
    "        tol = ppm_to_da(mass, tolerance)\n",
    "        lb_mass = mass - tol\n",
    "        ub_mass = mass + tol\n",
    "        lb_mass_key = math.floor(lb_mass)\n",
    "        ub_mass_key = math.floor(ub_mass)\n",
    "        hits += [x.sequence for x in kmers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "        if lb_mass_key != ub_mass_key:\n",
    "            hits += [x.sequence for x in kmers[ub_mass_key] if lb_mass <= x.mass <= ub_mass]\n",
    "            \n",
    "    return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a dictionary for sizes min length to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KmerMasses = namedtuple('KmerMasses', ['bs', 'bd', 'ys', 'yd'])\n",
    "\n",
    "def add_sequence_to_masssequences(l: list, sequence: str, mass: float) -> list:\n",
    "    '''\n",
    "    '''\n",
    "    for ms in l: \n",
    "        if ms.mass == float:\n",
    "            ms.sequences.append(sequence)\n",
    "            return l\n",
    "    l.append(MassSequences(mass, [sequence]))\n",
    "\n",
    "def build_kmer_mass_dicts(database: Database, min_peptide_len: int, max_peptide_len: int) -> KmerMasses:\n",
    "    '''\n",
    "    '''\n",
    "    bs = defaultdict(list)\n",
    "    bd = defaultdict(list)\n",
    "    ys = defaultdict(list)\n",
    "    yd = defaultdict(list)\n",
    "    \n",
    "    kmer_tracker = {}\n",
    "    \n",
    "    print(f'Indexing database for k={max_peptide_len}...')\n",
    "    database.set_kmer_size(max_peptide_len)\n",
    "    database.index()\n",
    "    print('Done')\n",
    "    mdl = len(database.metadata.keys())\n",
    "    \n",
    "    printskiplen = mdl // 1000\n",
    "    printskipc = 0\n",
    "    \n",
    "    for i, kmer in enumerate(list(database.metadata.keys())):\n",
    "        if len(kmer) < min_peptide_len: \n",
    "            continue\n",
    "            \n",
    "        if printskipc == printskiplen:\n",
    "            print(f'Looking at kmer {i + 1}/{mdl}\\r', end='')\n",
    "            printskipc = 0\n",
    "            \n",
    "        printskipc += 1\n",
    "        \n",
    "        endindex = min(len(kmer), max_peptide_len)\n",
    "        for i in range(min_peptide_len, endindex+1):\n",
    "            subseq = kmer[:i]\n",
    "            \n",
    "            if subseq in kmer_tracker:\n",
    "                continue\n",
    "            \n",
    "            kmer_tracker[subseq] = None # none takes up very little memory\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='b', charge=1)['spectrum'])\n",
    "            bs[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='b', charge=2)['spectrum'])\n",
    "            bd[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='y', charge=1)['spectrum'])\n",
    "            ys[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "            \n",
    "            subseqmass = max(gen_spectrum(subseq, ion='y', charge=2)['spectrum'])\n",
    "            yd[math.floor(subseqmass)].append(MassSequence(subseqmass, subseq))\n",
    "                    \n",
    "    del kmer_tracker\n",
    "        \n",
    "    return KmerMasses(bs, bd, ys, yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an alignment from the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_overlaps(seq1: str, seq2: str) -> str:\n",
    "    '''\n",
    "    '''\n",
    "    alignment = None\n",
    "    # if we have a perfect overlap, return it\n",
    "    if seq1 == seq2:\n",
    "        alignment = seq1\n",
    "    \n",
    "    # if one is a full subsequence of another, return the larger one\n",
    "    elif seq1 in seq2:\n",
    "        alignment = seq2\n",
    "    elif seq2 in seq1:\n",
    "        alignment = seq1\n",
    "    \n",
    "    else:\n",
    "        # try and find an alignment. seq2 should overlap as much of the right of seq1 as possible\n",
    "        start_points = [i for i in range(len(seq1)) if seq2[0] == seq1[i]]\n",
    "        for sp in start_points:\n",
    "            # try and see if extending it makes it match\n",
    "            for i in range(sp, len(seq1)):\n",
    "                if seq1[i] != seq2[i-sp]:\n",
    "                    break\n",
    "            if i == len(seq1) - 1:\n",
    "                s2_start = len(seq1) - sp\n",
    "                right_seq = seq2[s2_start] if s2_start < len(seq2) else ''\n",
    "                alignment = seq1 + seq2[s2_start:]\n",
    "            else:\n",
    "                alignment = seq1 + seq2\n",
    "    return alignment\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_alignment(seq1: str, seq2: str) -> (str, str):\n",
    "    '''\n",
    "    '''\n",
    "    alignment = ''\n",
    "    hybalignment = ''\n",
    "    attempted_overlap = align_overlaps(seq1, seq2)\n",
    "    if attempted_overlap and len(attempted_overlap) < len(seq1) + len(seq2):\n",
    "        # there is an overlap and some ambiguity\n",
    "        # get the starting point of seq2\n",
    "        rightstart = attempted_overlap.index(seq2)\n",
    "        leftend = len(seq1) - 1\n",
    "        # range between leftend and rigth start is ambiguous\n",
    "        alignment = attempted_overlap\n",
    "        hybalignment = attempted_overlap[:rightstart] + '(' + attempted_overlap[:rightstart:leftend+1] + ')' + attempted_overlap[leftend+1:]\n",
    "    else:\n",
    "        alignment = seq1 + seq2\n",
    "        hybalignment = seq1 + '-' + seq2\n",
    "        \n",
    "    return (alignment, hybalignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load fasta database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = '../../testing framework/data/databases/100prots.fasta'\n",
    "database = fasta.read(fasta_file, True)\n",
    "\n",
    "database = {x['name']: x for x in database}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Generate the peptides, hybrid proteins and peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hybrid protein 0/5[0%]\r",
      "Generating hybrid protein 1/5[20%]\r",
      "Generating hybrid protein 2/5[40%]\r",
      "Generating hybrid protein 3/5[60%]\r",
      "Generating hybrid protein 4/5[80%]\r\n",
      "Finished generating hybrid proteins\n",
      "QFN-KLP\n"
     ]
    }
   ],
   "source": [
    "test_directory = '../../testing framework/data/testing_output/'\n",
    "\n",
    "num_hybs = 5\n",
    "min_length= 5\n",
    "max_length = 35\n",
    "num_peptides = 100\n",
    "min_cont = 3 #min contribution for each side of a hybrid\n",
    "\n",
    "# make hybrid proteins\n",
    "hyb_prots = proteins.generate_hybrids([x for _, x in database.items()], num_hybs, min_contribution=max_length)\n",
    "# create peptides\n",
    "non_hybrid_peps = peptides.gen_peptides([x for _, x in database.items()], num_peptides, min_length=min_length, max_length=max_length, digest='random', dist='beta')\n",
    "# create hybrid peptides\n",
    "hyb_peps = peptides.gen_peptides(hyb_prots, num_hybs, min_length=min_length, max_length=max_length, digest='random', min_contribution=min_cont, hybrid_list=True)\n",
    "print(hyb_peps[0]['hybrid_sequence'])\n",
    "all_proteins_raw = [x for _,x in database.items()] + hyb_prots\n",
    "all_peptides_raw = non_hybrid_peps + hyb_peps\n",
    "\n",
    "peps = {}\n",
    "for i, pep in enumerate(all_peptides_raw):\n",
    "    peps[i] = pep\n",
    "    peps[i]['scan_no'] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = []\n",
    "sorted_keys = [int(c) for c in peps.keys()]\n",
    "sorted_keys.sort()\n",
    "for k in sorted_keys:\n",
    "    pep = peps[k]\n",
    "    cont = gen_spectrum(pep['sequence'])\n",
    "    spec = cont['spectrum']\n",
    "    pm = cont['precursor_mass']\n",
    "    spectra.append({'spectrum': spec, 'precursor_mass': pm})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the new kmer extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the kmer hash table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database...\n",
      "Adding protein 100/100 to tree\n",
      "Done.\n",
      "Building hashes for kmers...\n",
      "Indexing database for k=35...\n",
      "Done\n",
      "Looking at kmer 55051/55092\n",
      "Done. Time to complete: 85.35979509353638\n"
     ]
    }
   ],
   "source": [
    "indexing_st = time.time()\n",
    "\n",
    "print('Loading database...')\n",
    "db = Database(fasta_file)\n",
    "print('\\nDone.')\n",
    "\n",
    "print('Building hashes for kmers...')\n",
    "kmermasses = build_kmer_mass_dicts(db, min_cont, max_length)\n",
    "print(f'\\nDone. Time to complete: {time.time() - indexing_st}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On spectrum 345/345\n",
      "Done. Time to complete: 143.33s\n",
      "Time breakdown:         \n",
      "hash search time: 16.41s,\t 11%         \n",
      "results filtering time: 125.9s, \t 87%         \n",
      "alignment time: 0.96s, \t0%\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "hashsearchtime = 0\n",
    "alignmenttime = 0\n",
    "resultfilteringtime = 0\n",
    "\n",
    "speclen = len(spectra)\n",
    "alignments = {}\n",
    "for i, spec in enumerate(spectra):\n",
    "    print('On spectrum {}/{}\\r'.format(i + 1, speclen), end='')\n",
    "    hstst = time.time()\n",
    "    # find all of the basic hits first\n",
    "    s = Spectrum(spec['spectrum'])\n",
    "    bs, bd, ys, yd = search_kmers_hash(s, kmermasses.bs, 20), search_kmers_hash(s, kmermasses.bd, 20), search_kmers_hash(s, kmermasses.ys, 20), search_kmers_hash(s, kmermasses.yd, 20)\n",
    "    results = {\n",
    "        'bs': bs,\n",
    "        'bd': bd,\n",
    "        'ys': ys,\n",
    "        'yd': yd,\n",
    "    }\n",
    "    hashsearchtime += (time.time() - hstst)\n",
    "    #########################################################################\n",
    "    #                      BIGGEST TIME TAKER BLOCK\n",
    "    #########################################################################\n",
    "    rftst = time.time()\n",
    "    # narrow down the results to a few promising kmers\n",
    "    basemerhashedb = defaultdict(list)\n",
    "    basemerhashedy = defaultdict(list)\n",
    "    b_scores = []\n",
    "    y_scores = []\n",
    "    # hash by the base mer (in this case its 3)\n",
    "    for key, value in results.items():\n",
    "        if 'b' in key:\n",
    "            for val in value:\n",
    "                basemerb = val[:3]\n",
    "                if basemerb not in basemerhashedb:\n",
    "                    b_scores = insort_by_index((basemerb, score_subsequence(s.spectrum, basemerb)[0]), b_scores, 1)\n",
    "                basemerhashedb[basemerb].append(val)\n",
    "        else:\n",
    "            for val in value:\n",
    "                basemery = val[len(val)-3:]\n",
    "                if basemery not in basemerhashedy:\n",
    "                    y_scores = insort_by_index((basemery, score_subsequence(s.spectrum, basemery)[1]), y_scores, 1)\n",
    "                basemerhashedy[basemery].append(val)\n",
    "        \n",
    "    # sort by the score of the kmers\n",
    "#     b_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "#     y_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    toscoreb = []\n",
    "    toscorey = []\n",
    "    for basemerb in b_scores[::-1][:5]:\n",
    "        toscoreb += [basemerb[0]] + basemerhashedb[basemerb[0]]\n",
    "        \n",
    "    for basemery in y_scores[::-1][:5]:\n",
    "        toscorey += [basemery[0]] + basemerhashedy[basemery[0]]\n",
    "    \n",
    "    # flatten and filter by score\n",
    "#     bresults = [mer for merlist in [basemerhashedb[x[0]] for x in b_scores[:5]] for mer in merlist]\n",
    "#     yresults = [mer for merlist in [basemerhashedy[x[0]] for x in y_scores[:5]] for mer in merlist]\n",
    "    \n",
    "    best_b_results = sorted(toscoreb, key=lambda mer: score_subsequence(s.spectrum, mer)[0], reverse=True)[:5]\n",
    "    best_y_results = sorted(toscorey, key=lambda mer: score_subsequence(s.spectrum, mer)[1], reverse=True)[:5]\n",
    "    resultfilteringtime += time.time() - rftst\n",
    "    #########################################################################\n",
    "    #                      /BIGGEST TIME TAKER BLOCK\n",
    "    #########################################################################\n",
    "    atst = time.time()\n",
    "    # try and create an alignment\n",
    "    spec_alignments = []\n",
    "    for bs in best_b_results:\n",
    "        bproteins = [id_ for id_, _ in db.tree.find_all(bs)]\n",
    "        for ys in best_y_results:\n",
    "            yproteins = [id_ for id_, _ in db.tree.find_all(ys)]\n",
    "            \n",
    "            # the sequence is from the same protein, try and overlap it\n",
    "            if any([x in yproteins for x in bproteins]):\n",
    "                spec_alignments.append(align_overlaps(bs, ys))\n",
    "            # otherwise just concatenate them \n",
    "            else: \n",
    "                spec_alignments.append(bs + '-' + ys)\n",
    "        \n",
    "    # remove repeats\n",
    "    a = list(set([x for x in spec_alignments if x is not None]))\n",
    "    # sort them by their score agains the spectrum and save them\n",
    "    alignments[i] = sorted(a, key=lambda x: score_subsequence(spectra[i]['spectrum'], x.replace('-', '')), reverse=True)[:5]\n",
    "    alignmenttime += time.time() - atst\n",
    "ttime = time.time() - st\n",
    "print(f'\\nDone. Time to complete: {round(ttime, 2)}s')\n",
    "print(f'Time breakdown: \\\n",
    "        \\nhash search time: {round(hashsearchtime, 2)}s,\\t {int(100 * hashsearchtime/ttime)}% \\\n",
    "        \\nresults filtering time: {round(resultfilteringtime, 2)}s, \\t {int(100 * resultfilteringtime / ttime)}% \\\n",
    "        \\nalignment time: {round(alignmenttime, 2)}s, \\t{int(100 * alignmenttime/ttime)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how well it did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-hybrid accuracy: 100/100 [100%]\n",
      "Hybrid accuracy: 186/245 [75]%\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "misses = 0\n",
    "hbhits = 0\n",
    "hbmisses = 0\n",
    "\n",
    "badones = []\n",
    "hybridmisses = []\n",
    "hybridhits = []\n",
    "for i in range(len(alignments)):\n",
    "    if not len(alignments[i]):\n",
    "        print(f'missing alignment at {i}')\n",
    "        continue\n",
    "    hits\n",
    "    if 'hybrid' not in peps[i]['peptide_name'].lower() and alignments[i][0] == peps[i]['sequence']:\n",
    "        hits += 1\n",
    "    elif 'hybrid' in peps[i]['peptide_name'].lower() and alignments[i][0] == peps[i]['hybrid_sequence']:\n",
    "        hbhits += 1\n",
    "        hybridhits.append((alignments[i][0], peps[i]['hybrid_sequence']))\n",
    "    \n",
    "    # misses\n",
    "    else: \n",
    "        if 'hybrid' in peps[i]['peptide_name'].lower():\n",
    "            hbmisses += 1\n",
    "            hybridmisses.append((peps[i]['hybrid_sequence'], alignments[i]))\n",
    "        else:\n",
    "            misses += 1\n",
    "            badones.append((alignments[i][0], peps[i]['sequence']))\n",
    "#     print('attempted alignment: {} \\t actual sequence: {}'.format(alignments[i][0], peps[i]['sequence']))\n",
    "\n",
    "print(f'Non-hybrid accuracy: {hits}/{hits + misses} [{int(100 * hits / (hits + misses))}%]')\n",
    "print(f'Hybrid accuracy: {hbhits}/{hbhits + hbmisses} [{int(100 * hbhits / (hbhits + hbmisses))}]%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LIHLV', 'LLHLV')\n",
      "('LELSV', 'IELSV')\n",
      "('ISLSV', 'ISISV')\n",
      "('LNQGL', 'INQGL')\n",
      "('KKTEI', 'KKTEL')\n",
      "('TSKIS', 'TSKLS')\n",
      "('LIPTA', 'ILPTA')\n",
      "('EIKTL', 'ELKTL')\n",
      "('VWEAI', 'VWEAL')\n",
      "('FIGVDLIK-GVDLLK', 'FIGVDLIK')\n",
      "('LIIIL-LILLICM', 'LILLICM')\n",
      "('ELDRL', 'EIDRI')\n",
      "('LITLE', 'IITIE')\n",
      "('KLEKL', 'KIEKI')\n",
      "('LVLII', 'LVIIL')\n"
     ]
    }
   ],
   "source": [
    "for b in badones:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('QFN-KLP', ['QFIIE-KLP'])\n",
      "('QFN-KLPG', ['QFN-KIPG', 'QFN-KLPG', 'QFIIE-KLPG', 'QFIIE-LPG'])\n",
      "('GQFN-KLP', ['GQFN-KIP', 'GQFN-KLP', 'GGAIAFKTGKIP', 'GGAIAFKTGKLP'])\n",
      "('GQFN-KLPG', ['GQFN-KIPG', 'GQFN-KLPG', 'GQFN-PPGFTLPG', 'GQF-PPGFTLPG', 'GQF-KLPG'])\n",
      "('LKGQFN-KLP', ['LKGQFN-KIP', 'LKGQFN-KLP', 'LKGQF-KLP', 'LKGQF-KIP', 'LKGQKIP'])\n",
      "('ALKGQFN-KLPG', ['ALKGQFN-KIPG', 'ALKGQFN-KLPG', 'ALKGQFN-LPG', 'ALKGQF-KIPG', 'ALKGQF-KLPG'])\n",
      "('KALKGQFN-KLPG', ['KALKGQFN-KIPG', 'KALKGQFN-KLPG', 'KALKGQFN-LPG', 'KALKGQF-KIPG', 'KALKGQF-KLPG'])\n",
      "('ELE-HKN', ['EIEHKN', 'EIEHFIHKN', 'EIEHFI-IFKN', 'EIEH-LFKN', 'EIEHFI-LFKN'])\n",
      "('ELE-HKNV', ['EIEH-KNV', 'EIEH-HKNV'])\n",
      "('ELE-HKNVN', ['EIEH-KNVN', 'EIEH-HKNVN', 'EIEH-NVN'])\n",
      "('ELE-HKNVNS', ['EIEH-KNVNS', 'EIEH-HKNVNS', 'EIEH-NVNS'])\n",
      "('ELE-HKNVNSI', ['EIEH-KNVNSI', 'EIEH-HKNVNSI', 'EIEH-NVNSI'])\n",
      "('ELE-HKNVNSIE', ['EIEH-KNVNSIE', 'EIEH-NVNSIE', 'EIEH-HKNVNSIE'])\n",
      "('ELE-HKNVNSIEI', ['EIEH-KNVNSIEI', 'EIEH-HKNVNSIEI', 'EIEH-NVNSIEI'])\n",
      "('AELE-HKN', ['AEIE-HKN', 'AELE-HKN', 'AEIE-PSYVDKN', 'AELE-PSYVDKN'])\n",
      "('AELE-HKNV', ['AEIE-HKNV', 'AELE-HKNV', 'AEL-HKNV'])\n",
      "('AELE-HKNVN', ['AEIE-HKNVN', 'AELE-HKNVN', 'AEIE-KNVN', 'AELE-KNVN', 'AEIE-NVN'])\n",
      "('AELE-HKNVNS', ['AEIE-HKNVNS', 'AELE-HKNVNS', 'AEIE-KNVNS', 'AELE-KNVNS', 'AEIE-NVNS'])\n",
      "('IGA-LAT', ['IGAI-ALAT', 'LGAL-AIAT', 'LGAL-ALAT', 'IGAI-AIAT', 'LGAL-QLAT'])\n",
      "('IGA-LATL', ['IGAI-LATL', 'LGAL-LATI', 'IGAI-IATI', 'IGAI-LATI', 'LGAL-LATL'])\n",
      "('IGA-LATLV', ['LGAL-ATLV', 'LGAL-ATIV', 'IGAI-ATLV', 'IGAI-ATIV', 'IGAI-LATLV'])\n",
      "('IGA-LATLVA', ['IGAI-ATLVA', 'LGAL-ATLVA', 'LQIA-TIVA', 'LGAL-LATLVA', 'IGAI-LATLVA'])\n",
      "('IGA-LATLVAT', ['LGAL-ATLVAT', 'IGAI-ATLVAT', 'LQIA-TLVAT', 'IGAI-TLVAT', 'LGAL-TLVAT'])\n",
      "('IGA-LATLVATA', ['IGAI-ATLVATA', 'LGAL-ATLVATA', 'LQIA-TLVATA', 'LGAL-TLVATA', 'IGAI-TLVATA'])\n",
      "('IGA-LATLVATAW', ['IGAI-ATLVATAW', 'LGAL-ATLVATAW', 'LQIA-TLVATAW', 'LGAL-TLVATAW', 'IGAI-TLVATAW'])\n",
      "('TIGA-LAT', ['TLQL-AIAT', 'TIQL-ALAT', 'TIQL-AIAT', 'TLQL-ALAT', 'TIGA-AIAT'])\n",
      "('QTIGA-LAT', ['QTIG-AIAT', 'QTIG-ALAT', 'QTIGA-AIAT', 'QTIGA-ALAT', 'QTIGA-QLAT'])\n",
      "('QTIGA-LATL', ['QTIGA-LATI', 'QTIGA-LATL', 'QTIGA-IATI', 'QTLQ-LATL', 'QTLQ-LATI'])\n",
      "('QQTIGA-LAT', ['QQTIG-ALAT', 'QQTI-QLAT', 'QQTIGA-LTHT', 'QQTIGA-ALAT', 'QQTIGA-QLAT'])\n",
      "('QQTIGA-LATL', ['QQTIGA-IATI', 'QQTIGA-LATL', 'QQTIGA-IATL', 'QQTIG-IATI', 'QQTIG-LATL'])\n",
      "('NQQTIGA-LAT', ['NQQTIG-ALAT', 'NQQTIG-AIAT', 'NQQTI-QLAT', 'NQQTIGA-AIAT', 'NQQTIGA-ALAT'])\n",
      "('NQQTIGA-LATL', ['NQQTIGA-LATI', 'NQQTIGA-LATL', 'NQQTIGA-IATI', 'NQQTIG-LATI', 'NQQTIG-IATI'])\n",
      "('RNQQTIGA-LAT', ['RNQQTIG-ALAT', 'RNQQTIG-AIAT', 'RNQQTI-QLAT', 'RNQQTIGA-AIAT', 'RNQQTIGA-ALAT'])\n",
      "('RNQQTIGA-LATL', ['RNQQTIGA-LATI', 'RNQQTIGA-IATI', 'RNQQTIGA-LATL', 'RNQQTIG-IATI', 'RNQQTIG-LATL'])\n",
      "('VRNQQTIGA-LAT', ['VRNQQTIG-AIAT', 'VRNQQTIG-ALAT', 'VRNQQTI-QLAT', 'VRNQQTIGA-AIAT', 'VRNQQTIGA-ALAT'])\n",
      "('VRNQQTIGA-LATL', ['VRNQQTIGA-LATI', 'VRNQQTIGA-IATI', 'VRNQQTIGA-LATL', 'VRNQQTIG-LATL', 'VRNQQTIG-LATI'])\n",
      "('NKG-LST', ['NKG-IST', 'NKGI-GLST', 'NKGI-IST', 'NKG-GLST'])\n",
      "('NKG-LSTP', ['NKGI-STP', 'NKG-LSTP', 'NKGI-LPSPATFALSTP', 'NKG-LPSPATFALSTP', 'NKGI-LSTP'])\n",
      "('NKG-LSTPP', ['NKGI-STPP', 'NKG-LSTPP', 'NKGI-SLSTPP', 'NKGI-LSTPP', 'NKG-SLSTPP'])\n",
      "('NKG-LSTPPC', ['NKGI-STPPC', 'NKG-LSTPPC', 'NKGI-LSTPPC', 'NKGI-TPPC', 'NKG-STPPC'])\n",
      "('NKG-LSTPPCS', ['NKGI-STPPCS', 'NKG-LSTPPCS', 'NKGI-TPPCS', 'NKGI-LSTPPCS', 'NKG-STPPCS'])\n",
      "('NKG-LSTPPCSE', ['NKGI-STPPCSE', 'NKG-LSTPPCSE', 'NKGI-TPPCSE', 'NKGI-LSTPPCSE', 'NKG-STPPCSE'])\n",
      "('VNKG-LST', ['VNK-GLST', 'VNKG-IST', 'VNKG-GLST', 'VNGKLS-GLST', 'VNGKLS-IST'])\n",
      "('KVNKG-LST', ['KVNKG-IST', 'KVNK-GLST', 'KVNKG-GLST', 'KVNK-IST', 'KVN-GLST'])\n",
      "('GDKVNKG-LST', ['GDKVNK-GLST', 'GDKVNKG-IST', 'GDKVNKGFQPLV-GLST', 'GDKVNKGFQPLV-IST', 'GDKVNKG-GLST'])\n",
      "('VGDKVNKG-LST', ['VGDKVNK-GLST', 'VGDKVNKG-IST', 'VGDKVNKG-GLST', 'VGDKVNK-IST', 'VGDKVN-GLST'])\n",
      "('EVGDKVNKG-LST', ['EVGDKVNKG-IST', 'EVGDKVNK-GLST', 'EVGDKVNKG-GLST', 'EVGDKVNK-IST', 'EVGDKVN-GLST'])\n",
      "('KET-GLL', ['KEGTL', 'KET-TGIL', 'KET-TGLL', 'KEGT-TGLL', 'KEGT-TGIL'])\n",
      "('EKET-GLL', ['EKE-TGIL', 'EKE-TGLL', 'EKET-TGIL', 'EKET-TGLL'])\n",
      "('EKET-GLLL', ['EKE-TGILI', 'EKE-TGLLL', 'EKET-GLLL', 'EKET-TGLLL', 'EKET-TGILI'])\n",
      "('SEKET-GLL', ['SEKE-TGIL', 'SEKE-TGLL', 'SEKET-TGLL', 'SEKET-TGIL', 'SEK-TGLL'])\n",
      "('SEKET-GLLL', ['SEKE-TGILI', 'SEKET-GLLL', 'SEKE-TGLLL', 'SEKET-TGILI', 'SEKET-TGLLL'])\n",
      "('GSEKET-GLLL', ['GSEKE-TGLLL', 'GSEKE-TGILI', 'GSEKET-GLLL', 'GSEKET-TGILI', 'GSEKET-TGLLL'])\n",
      "('TGSEKET-GLL', ['TGSEKE-TGLL', 'TGSEKE-TGIL', 'TGSEKET-TTTCQVVGLL', 'TGSEKETKSG-TTTCQVVGLL', 'TGSEKETKSG-TGIL'])\n",
      "('TGSEKET-GLLL', ['TGSEKE-TGLLL', 'TGSEKE-TGILI', 'TGSEKETKSG-TTTCQVVGLLL', 'TGSEKET-TTTCQVVGLLL', 'TGSEKETKSG-TGILI'])\n",
      "('STGSEKET-GLL', ['STGSEKE-TGLL', 'STGSEKE-TGIL', 'STGSEKET-TGIL', 'STGSEKET-TGLL', 'STGSEKE-TTTCQVVGLL'])\n",
      "('STGSEKET-GLLL', ['STGSEKE-TGILI', 'STGSEKE-TGLLL', 'STGSEKET-TGLLL', 'STGSEKET-TGILI', 'STGSEKET-TTTCQVVGLLL'])\n",
      "('RSTGSEKET-GLL', ['RSTGSEKE-TGLL', 'RSTGSEKE-TGIL', 'RSTGSEKET-TGIL', 'RSTGSEKET-TGLL', 'RSTGSEKET-TTTCQVVGLL'])\n",
      "('RSTGSEKET-GLLL', ['RSTGSEKE-TGILI', 'RSTGSEKE-TGLLL', 'RSTGSEKET-TGILI', 'RSTGSEKET-TGLLL', 'RSTGSEKET-TTTCQVVGLLL'])\n"
     ]
    }
   ],
   "source": [
    "for hm in hybridmisses:\n",
    "    print(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spectrum': [132.04776143499998,\n",
       "  203.084875435,\n",
       "  316.16893943499997,\n",
       "  502.248252435,\n",
       "  573.285366435],\n",
       " 'precursor_mass': 591.2959311000001}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_spectrum('MALWA', ion='b', charge=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
